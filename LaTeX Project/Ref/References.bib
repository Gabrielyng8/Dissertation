@article{szeliski_computer_nodate,
	title = {Computer Vision: Algorithms and Applications, 2nd Edition},
	author = {Szeliski, Richard},
	langid = {english},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\G5SAVPU3\\Szeliski - Computer Vision Algorithms and Applications, 2nd Edition.pdf:application/pdf},
}

@book{bradski_learning_2011,
	location = {Beijing},
	edition = {1. ed., [Nachdr.]},
	title = {Learning {OpenCV}: computer vision with the {OpenCV} library},
	isbn = {978-0-596-51613-0},
	series = {Software that sees},
	shorttitle = {Learning {OpenCV}},
	pagetotal = {555},
	publisher = {O'Reilly},
	author = {Bradski, Gary R. and Kaehler, Adrian},
	date = {2011},
	langid = {english},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\36NISWUN\\Bradski and Kaehler - 2011 - Learning OpenCV computer vision with the OpenCV library.pdf:application/pdf},
}

@article{the_math_works_inc_math_1991,
	title = {The Math Works Inc},
	volume = {57},
	rights = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
	issn = {0037-5497, 1741-3133},
	url = {https://journals.sagepub.com/doi/10.1177/003754979105700407},
	doi = {10.1177/003754979105700407},
	pages = {240--240},
	number = {4},
	journaltitle = {{SIMULATION}},
	shortjournal = {{SIMULATION}},
	author = {{The Math Works, Inc.}},
	urldate = {2026-01-01},
	date = {1991-10},
	langid = {english},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\TQHAZAT6\\The Math Works, Inc. - 1991 - The Math Works Inc.pdf:application/pdf},
}

@misc{fan_deep_2022,
	title = {Deep Learning on Monocular Object Pose Detection and Tracking: A Comprehensive Overview},
	url = {http://arxiv.org/abs/2105.14291},
	doi = {10.48550/arXiv.2105.14291},
	shorttitle = {Deep Learning on Monocular Object Pose Detection and Tracking},
	abstract = {Object pose detection and tracking has recently attracted increasing attention due to its wide applications in many areas, such as autonomous driving, robotics, and augmented reality. Among methods for object pose detection and tracking, deep learning is the most promising one that has shown better performance than others. However, survey study about the latest development of deep learning-based methods is lacking. Therefore, this study presents a comprehensive review of recent progress in object pose detection and tracking that belongs to the deep learning technical route. To achieve a more thorough introduction, the scope of this study is limited to methods taking monocular {RGB}/{RGBD} data as input and covering three kinds of major tasks: instance-level monocular object pose detection, category-level monocular object pose detection, and monocular object pose tracking. In our work, metrics, datasets, and methods of both detection and tracking are presented in detail. Comparative results of current state-of-the-art methods on several publicly available datasets are also presented, together with insightful observations and inspiring future research directions.},
	number = {{arXiv}:2105.14291},
	publisher = {{arXiv}},
	author = {Fan, Zhaoxin and Zhu, Yazhi and He, Yulin and Sun, Qi and Liu, Hongyan and He, Jun},
	urldate = {2026-01-01},
	date = {2022-04-21},
	eprinttype = {arxiv},
	eprint = {2105.14291 [cs]},
	note = {version: 2},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\65UCCLIG\\Fan et al. - 2022 - Deep Learning on Monocular Object Pose Detection and Tracking A Comprehensive Overview.pdf:application/pdf;Snapshot:C\:\\Users\\Gabriel\\Zotero\\storage\\GQZZ4ENJ\\2105.html:text/html},
}

@article{mandal_object_2020,
	title = {Object Detection and Tracking Algorithms for Vehicle Counting: A Comparative Analysis},
	volume = {2},
	issn = {2523-3556, 2523-3564},
	url = {http://link.springer.com/10.1007/s42421-020-00025-w},
	doi = {10.1007/s42421-020-00025-w},
	shorttitle = {Object Detection and Tracking Algorithms for Vehicle Counting},
	abstract = {The rapid advancement in the field of deep learning and high performance computing has highly augmented the scope of video-based vehicle counting system. In this paper, the authors deploy several state-of-the-art object detection and tracking algorithms to detect and track different classes of vehicles in their regions of interest ({ROI}). The goal of correctly detecting and tracking vehicles’ in their {ROI} is to obtain an accurate vehicle count. Multiple combinations of object detection models coupled with different tracking systems are applied to access the best vehicle counting framework. The models’ addresses challenges associated to different weather conditions, occlusion and low-light settings and efficiently extracts vehicle information and trajectories through its computationally rich training and feedback cycles. The automatic vehicle counts resulting from all the model combinations are validated and compared against the manually counted ground truths of over 9 hours’ traffic video data obtained from the Louisiana Department of Transportation and Development. Experimental results demonstrate that the combination of {CenterNet} and Deep {SORT}, Detectron2 and Deep {SORT}, and {YOLOv}4 and Deep {SORT} produced the best overall counting percentage for all vehicles.},
	pages = {251--261},
	number = {3},
	journaltitle = {Journal of Big Data Analytics in Transportation},
	shortjournal = {J. Big Data Anal. Transp.},
	author = {Mandal, Vishal and Adu-Gyamfi, Yaw},
	urldate = {2026-01-01},
	date = {2020-12},
	langid = {english},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\MFJ7IFJY\\Mandal and Adu-Gyamfi - 2020 - Object Detection and Tracking Algorithms for Vehicle Counting A Comparative Analysis.pdf:application/pdf},
}

@inproceedings{briechle_template_2001,
	location = {Orlando, {FL}},
	title = {Template matching using fast normalized cross correlation},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=914530},
	doi = {10.1117/12.421129},
	eventtitle = {Aerospace/Defense Sensing, Simulation, and Controls},
	pages = {95--102},
	author = {Briechle, Kai and Hanebeck, Uwe D.},
	editor = {Casasent, David P. and Chao, Tien-Hsin},
	urldate = {2026-01-02},
	date = {2001-03-20},
	langid = {english},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\DMK9S39T\\Briechle and Hanebeck - 2001 - Template matching using fast normalized cross correlation.pdf:application/pdf},
}

@article{reddy_fft-based_1996,
	title = {An {FFT}-based technique for translation, rotation, and scale-invariant image registration},
	volume = {5},
	issn = {1941-0042},
	url = {https://ieeexplore.ieee.org/document/506761},
	doi = {10.1109/83.506761},
	abstract = {This correspondence discusses an extension of the well-known phase correlation technique to cover translation, rotation, and scaling. Fourier scaling properties and Fourier rotational properties are used to find scale and rotational movement. The phase correlation technique determines the translational movement. This method shows excellent robustness against random noise.},
	pages = {1266--1271},
	number = {8},
	journaltitle = {{IEEE} Transactions on Image Processing},
	author = {Reddy, B.S. and Chatterji, B.N.},
	urldate = {2026-01-02},
	date = {1996-08},
	keywords = {Computational efficiency, Correlation, Fourier transforms, Frequency domain analysis, Image processing, Image registration, Noise robustness, Optimal matching, Phase noise, Pixel},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\QMP96E5U\\Reddy and Chatterji - 1996 - An FFT-based technique for translation, rotation, and scale-invariant image registration.pdf:application/pdf},
}

@article{han_reliable_2021,
	title = {Reliable Template Matching for Image Detection in Vision Sensor Systems},
	volume = {21},
	issn = {1424-8220},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC8706661/},
	doi = {10.3390/s21248176},
	abstract = {Template matching is a simple image detection algorithm that can easily detect different types of objects just by changing the template without tedious training procedures. Despite these advantages, template matching is not currently widely used. This is because traditional template matching is not very reliable for images that differ from the template. The reliability of template matching can be improved by using additional information (depths for the template) available from the vision sensor system. Methods of obtaining the depth of a template using stereo vision or a few (two or more) template images or a short template video via mono vision are well known in the vision literature and have been commercialized. In this strategy, this paper proposes a template matching vision sensor system that can easily detect various types of objects without prior training. To this end, by using the additional information provided by the vision sensor system, we study a method to increase the reliability of template matching, even when there is a difference in the 3D direction and size between the template and the image. Template images obtained through the vision sensor provide a depth template. Using this depth template, it is possible to predict the change of the image according to the difference in the 3D direction and the size of the object. Using the predicted changes in these images, the template is calibrated close to the given image, and then template matching is performed. For ease of use, the algorithm is proposed as a closed form solution that avoids tedious recursion or training processes. For wider application and more accurate results, the proposed method considers the 3D direction and size difference in the perspective projection model and the general 3D rotation model.},
	pages = {8176},
	number = {24},
	journaltitle = {Sensors (Basel, Switzerland)},
	shortjournal = {Sensors (Basel)},
	author = {Han, Youngmo},
	urldate = {2026-01-02},
	date = {2021-12-07},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\FTNJHN7G\\Han - 2021 - Reliable Template Matching for Image Detection in Vision Sensor Systems.pdf:application/pdf},
}

@article{song_object_2025,
	title = {Object Detection based on {HSV} in {OpenCV}},
	volume = {121},
	doi = {10.54254/2755-2721/2025.19740},
	abstract = {In the realm of computer vision and automation, the ability to identify and track objects in real time is critical for various applications, including robotics, surveillance, and machine control. This paper explores the process of controlling a Raspberry Pi computer equipped with a camera to detect and locate circular objects with a green color. By leveraging the power of open-source libraries and image processing techniques, the system performs real-time analysis of camera input to identify target objects based on color and shape. The research employs a literature review methodology, synthesizing information from relevant studies on computer vision, object recognition, and color filtering techniques. The paper focuses on the use of algorithms for color segmentation, contour detection, and shape recognition to achieve accurate object identification. Through this method, it examines the effectiveness and limitations of using a Raspberry Pi for object detection tasks in constrained environments. The findings indicate that Raspberry Pi, when coupled with optimized algorithms, provides a cost-effective solution for basic object detection tasks, though its performance is limited by processing power compared to more robust systems. This review emphasizes the significance of affordable solutions for educational and small-scale automation purposes, highlighting their potential impact on future applications in low-cost robotics and {IoT} devices.},
	pages = {116--122},
	journaltitle = {Applied and Computational Engineering},
	shortjournal = {Applied and Computational Engineering},
	author = {Song, Puchuan},
	date = {2025-01-10},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\BK9QUFNS\\Song - 2025 - Object Detection based on HSV in OpenCV.pdf:application/pdf},
}

@inproceedings{liu_ssd_2016,
	location = {Cham},
	title = {{SSD}: Single Shot {MultiBox} Detector},
	isbn = {978-3-319-46448-0},
	doi = {10.1007/978-3-319-46448-0_2},
	shorttitle = {{SSD}},
	abstract = {We present a method for detecting objects in images using a single deep neural network. Our approach, named {SSD}, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. {SSD} is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes {SSD} easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the {PASCAL} {VOC}, {COCO}, and {ILSVRC} datasets confirm that {SSD} has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. For \$\$300 {\textbackslash}times 300\$\$300×300input, {SSD} achieves 74.3 \% {mAP} on {VOC}2007 test at 59 {FPS} on a Nvidia Titan X and for \$\$512 {\textbackslash}times 512\$\$512×512input, {SSD} achieves 76.9 \% {mAP}, outperforming a comparable state of the art Faster R-{CNN} model. Compared to other single stage methods, {SSD} has much better accuracy even with a smaller input image size. Code is available at https://github.com/weiliu89/caffe/tree/ssd.},
	pages = {21--37},
	booktitle = {Computer Vision – {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	date = {2016},
	langid = {english},
	keywords = {Convolutional neural network, Real-time object detection},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\R9LLVJVJ\\Liu et al. - 2016 - SSD Single Shot MultiBox Detector.pdf:application/pdf},
}

@article{gholinavaz_robustness_2025,
	title = {Robustness analysis of {YOLO} and faster R-{CNN} for object detection in realistic weather scenarios with noise augmentation},
	volume = {15},
	rights = {2025 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-025-28737-5},
	doi = {10.1038/s41598-025-28737-5},
	abstract = {Object detection systems are central to the autonomy and safety of intelligent transportation systems. Yet, the accuracy of object detection models can suffer under environmental noise or adverse weather. This paper tested the robustness of four object detection architectures: {YOLOv}5s, {YOLOv}8m, {YOLOv}10n, and Faster R-{CNN}, to visual degradation (real-world weather and artificial noise). We utilize the {DAWN} dataset, a benchmark of 1,000 high-resolution traffic images captured under fog, rain, snow, and sandstorms, with further augmentations of Gaussian noise, salt-and-pepper noise, blurriness, and overlays applied with artificial fog. We standardized all annotations to {YOLO} and {COCO} annotation formats for multi-framework interoperability. Our quantitative analysis used {mAP}@0.5, {mAP}@0.5:0.95, Precision, and Recall to compare the models, alongside some qualitative analysis through visual overlays and plotting training loss. The findings of our analysis showed {YOLOv}8m achieved the highest baseline accuracy on clean data, while Faster R-{CNN} proved resilient in noisy environments. {YOLOv}10n achieves a good trade-off between efficient and robust detection. The results of this study highlight the necessity of adaptive training pipelines and environment-aware benchmarks to enhance the real-world reliability of vision-based detection systems.},
	pages = {44888},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	publisher = {Nature Publishing Group},
	author = {Gholinavaz, Sana and Saeedi, Nima and Gharehveran, Sina Samadi},
	urldate = {2026-01-03},
	date = {2025-12-29},
	langid = {english},
	keywords = {Engineering, Environmental sciences, Mathematics and computing},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\43VPCUVI\\Gholinavaz et al. - 2025 - Robustness analysis of YOLO and faster R-CNN for object detection in realistic weather scenarios wit.pdf:application/pdf},
}

@article{yao_hp-yolov8_2024,
	title = {{HP}-{YOLOv}8: High-Precision Small Object Detection Algorithm for Remote Sensing Images},
	volume = {24},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/24/15/4858},
	doi = {10.3390/s24154858},
	shorttitle = {{HP}-{YOLOv}8},
	abstract = {{YOLOv}8, as an efficient object detection method, can swiftly and precisely identify objects within images. However, traditional algorithms encounter difficulties when detecting small objects in remote sensing images, such as missing information, background noise, and interactions among multiple objects in complex scenes, which may affect performance. To tackle these challenges, we propose an enhanced algorithm optimized for detecting small objects in remote sensing images, named {HP}-{YOLOv}8. Firstly, we design the C2f-D-Mixer (C2f-{DM}) module as a replacement for the original C2f module. This module integrates both local and global information, significantly improving the ability to detect features of small objects. Secondly, we introduce a feature fusion technique based on attention mechanisms, named Bi-Level Routing Attention in Gated Feature Pyramid Network ({BGFPN}). This technique utilizes an efficient feature aggregation network and reparameterization technology to optimize information interaction between different scale feature maps, and through the Bi-Level Routing Attention ({BRA}) mechanism, it effectively captures critical feature information of small objects. Finally, we propose the Shape Mean Perpendicular Distance Intersection over Union ({SMPDIoU}) loss function. The method comprehensively considers the shape and size of detection boxes, enhances the model’s focus on the attributes of detection boxes, and provides a more accurate bounding box regression loss calculation method. To demonstrate our approach’s efficacy, we conducted comprehensive experiments across the {RSOD}, {NWPU} {VHR}-10, and {VisDrone}2019 datasets. The experimental results show that the {HP}-{YOLOv}8 achieves 95.11\%, 93.05\%, and 53.49\% in the {mAP}@0.5 metric, and 72.03\%, 65.37\%, and 38.91\% in the more stringent {mAP}@0.5:0.95 metric, respectively.},
	pages = {4858},
	number = {15},
	journaltitle = {Sensors},
	publisher = {Multidisciplinary Digital Publishing Institute},
	author = {Yao, Guangzhen and Zhu, Sandong and Zhang, Long and Qi, Miao},
	urldate = {2026-01-03},
	date = {2024-01},
	langid = {english},
	keywords = {attention mechanism, feature fusion, remote sensing images, small object detection, {YOLOv}8},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\HAN6423P\\Yao et al. - 2024 - HP-YOLOv8 High-Precision Small Object Detection Algorithm for Remote Sensing Images.pdf:application/pdf},
}

@article{chen_design_2025,
	title = {Design of a real-time abnormal detection system for rotating machinery based on {YOLOv}8},
	volume = {11},
	issn = {2297-3079},
	url = {https://www.frontiersin.org/journals/mechanical-engineering/articles/10.3389/fmech.2025.1683572/full},
	doi = {10.3389/fmech.2025.1683572},
	abstract = {To address the issues of low detection accuracy and poor real-time performance in existing methods for detecting minor abnormalities such as cracks, oil leaks, and loose bolts in rotating industrial machinery under dynamic vibration conditions, this paper proposes a lightweight detection system based on {YOLOv}8 (You Only Look Once version 8) with adaptive feature enhancement. First, this paper employs a temporal motion compensation module based on optical flow to estimate and correct the vibration displacement between adjacent frames. Second, this paper designs a lightweight {YOLOv}8 network, using depthwise separable convolution instead of traditional convolution. Finally, this paper employs a weighted fusion strategy to improve the accuracy of small object detection in complex backgrounds. This model is deployed on the Jetson {AGX} Xavier edge computing platform, utilizing {FP}16 (half-precision floating-point) / {INT}8 (8-bit integer) quantization and asynchronous pipeline inference to ensure real-time processing capabilities on edge devices. The experimental results show that the method achieves an average detection accuracy of 97.8\% ({mAP}@0.5) and 86.6\% ({mAP}@0.5:0.95), with an average inference speed of 29.5 {FPS} (frames per second). This demonstrates that the method has reached industrial-grade performance in terms of detection accuracy, real-time performance, and deployment stability, making it highly valuable for practical applications.},
	journaltitle = {Frontiers in Mechanical Engineering},
	shortjournal = {Front. Mech. Eng.},
	publisher = {Frontiers},
	author = {Chen, Jianli and Tong, Jie and Su, Jiang},
	urldate = {2026-01-03},
	date = {2025-10-07},
	keywords = {anomaly detection, lightweight network, real-time detection, rotating machinery, {YoloV}8 model},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\MX6RT3ZY\\Chen et al. - 2025 - Design of a real-time abnormal detection system for rotating machinery based on YOLOv8.pdf:application/pdf},
}

@article{afifah_yolov8_2026,
	title = {{YOLOv}8 for Object Detection: A Comprehensive Review of Advances,Techniques, and Applications},
	volume = {2},
	rights = {Copyright (c) 2026 Vivi Afifah, Surni Erniwati (Author)},
	issn = {3089-7483},
	url = {https://www.journal.cendekiajournal.com/ijaci/article/view/25},
	doi = {10.71129/ijaci.v2i1.pp53-61},
	shorttitle = {{YOLOv}8 for Object Detection},
	abstract = {This paper presents a review focusing on the most current advancements in object detection techniques using {YOLOv}8 and their applications across a range of fields, such as surveillance systems, autonomous driving, smart agriculture, industrial quality control, and medical image analysis. {YOLOv}8, launched by Ultralytics in early 2023, represents the newest evolution of the You Only Look Once framework., {YOLOv}8 demonstrates notable improvements in both detection accuracy and processing speed compared to earlier versions. This review explores key updates in {YOLOv}8’s architecture, including enhanced backbone designs, efficient training processes, and optimized loss functions, alongside the incorporation of attention mechanisms and compact model structures. These findings from 40+ selected studies confirm {YOLOv}8’s potential as a reliable and efficient solution for object detection tasks in both academic research and real-world applications. This study serves as a comprehensive reference for researchers and practitioners seeking to optimize aiming to enhance {YOLOv}8-based models across diverse practical applications.},
	pages = {53--61},
	number = {1},
	journaltitle = {{IJACI} : International Journal of Advanced Computing and Informatics},
	author = {Afifah, Vivi and Erniwati, Surni},
	urldate = {2026-01-03},
	date = {2026},
	langid = {english},
	keywords = {{YOLOv}8, Computer Vision, Data Augmentation, Deep Learning, Object Detection},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\ALQSNBU5\\Afifah and Erniwati - 2026 - YOLOv8 for Object Detection A Comprehensive Review of Advances,Techniques, and Applications.pdf:application/pdf},
}


@article{wei_iterative_2024,
	title = {Iterative Camera Calibration Method Based on Concentric Circle Grids},
	volume = {14},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/14/5/1813},
	doi = {10.3390/app14051813},
	abstract = {A concentric circle target is commonly used in the vision measurement system for its detection accuracy and robustness. To enhance the camera calibrat...},
	number = {5},
	journaltitle = {Applied Sciences},
	publisher = {publisher},
	author = {Wei, Liang and Huo, Ju and Yue, Lin},
	urldate = {2026-02-02},
	date = {2024-02-22},
	langid = {english},
	keywords = {concentric circle, cross-ratio invariance, iterative camera calibration, lens distortion},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\79M9JL6W\\Wei et al. - 2024 - Iterative Camera Calibration Method Based on Concentric Circle Grids.pdf:application/pdf},
}

@article{peng_high-precision_2025,
	title = {High-precision camera calibration based on concentric circle compensation for industrial environments},
	volume = {33},
	rights = {© 2025 Optica Publishing Group},
	issn = {1094-4087},
	url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-33-25-52503},
	doi = {10.1364/OE.555803},
	abstract = {Accurate calibration of cameras in industrial production vision systems is a critical fundamental task. However, industrial visual measurement systems often face challenges such as large fields of view, shallow depths of field, and the use of imprecise large calibration templates. These factors make the task of accurate visual measurement in the industrial production environment a great challenge. This paper presents a camera calibration algorithm based on the eccentricity error of concentric circles and the fixed topological relationship constraints of the calibration board structure. In this calibration algorithm, the homography relationship of the calibration board targets is calculated to iteratively optimize the eccentricity error of the concentric circle patterns, providing stable and accurate feature point information for precise camera calibration in industrial settings. Additionally, during the iterative calibration process, deviation parameters are introduced for each feature point on the calibration board relative to the standard plane to account for the machining and geometric deformation errors of the calibration board. This approach addresses issues related to the imprecise calibration of large planar templates. These deviation parameters and eccentricity errors of the concentric circle feature points are optimized together with the camera calibration parameters to correct the positions of the feature points and enhance the camera calibration accuracy in complex industrial scenarios. The results of simulation and experiments validate the feasibility and operability of the proposed camera calibration method. It can fundamentally eliminate perspective transformation errors and improve the precision of camera parameters and target geometry.},
	pages = {52503--52522},
	number = {25},
	journaltitle = {Optics Express},
	shortjournal = {Opt. Express, {OE}},
	publisher = {Optica Publishing Group},
	author = {Peng, Tao and Gu, Anqi and Fang, Dujuan and Zhang, Zhijiang},
	urldate = {2026-02-02},
	date = {2025-12-15},
	keywords = {Calibration, Camera calibration, Image metrics, Imaging systems, Physiology, Three dimensional reconstruction},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\5IAGDMJP\\Peng et al. - 2025 - High-precision camera calibration based on concentric circle compensation for industrial environment.pdf:application/pdf},
}

@misc{hinderer_groundgazer_2025,
	title = {{GroundGazer}: Camera-based indoor localization of mobile robots with millimeter accuracy at low cost},
	url = {http://arxiv.org/abs/2509.17346},
	doi = {10.48550/arXiv.2509.17346},
	shorttitle = {{GroundGazer}},
	abstract = {Highly accurate indoor localization systems with mm positioning accuracy are currently very expensive. They include range finders (such as {LiDAR}), tachymeters, and motion capture systems relying on multiple high-end cameras. In this work, we introduce a high-accuracy, planar indoor localization system named {GroundGazer} ({GG}) for autonomous mobile robots ({AMRs}). {GG} estimates the {AMR}'s position with mm and its heading with sub-degree accuracy. The system requires only a monocular (fisheye) camera, a chessboard floor, and an optional laser diode. Our system is simple and low-cost, easy to set up, portable, robust, scalable to large areas and robot swarms, and potentially extendable to 3D position and orientation estimation.},
	number = {{arXiv}:2509.17346},
	publisher = {{arXiv}},
	author = {Hinderer, Sven and Hüsken, Jakob and Sun, Bohan and Yang, Bin},
	urldate = {2026-02-02},
	date = {2025-12-30},
	eprinttype = {arxiv},
	eprint = {2509.17346 [eess]},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Preprint PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\C236A5PL\\Hinderer et al. - 2025 - GroundGazer Camera-based indoor localization of mobile robots with millimeter accuracy at low cost.pdf:application/pdf;Snapshot:C\:\\Users\\Gabriel\\Zotero\\storage\\K5YZGK84\\2509.html:text/html},
}

@misc{jiang_accurate_2025,
	title = {On Accurate and Robust Estimation of 3D and 2D Circular Center: Method and Application to Camera-Lidar Calibration},
	url = {http://arxiv.org/abs/2511.06611},
	doi = {10.48550/arXiv.2511.06611},
	shorttitle = {On Accurate and Robust Estimation of 3D and 2D Circular Center},
	abstract = {Circular targets are widely used in {LiDAR}-camera extrinsic calibration due to their geometric consistency and ease of detection. However, achieving accurate 3D-2D circular center correspondence remains challenging. Existing methods often fail due to decoupled 3D fitting and erroneous 2D ellipse-center estimation. To address this, we propose a geometrically principled framework featuring two innovations: (i) a robust 3D circle center estimator based on conformal geometric algebra and {RANSAC}; and (ii) a chord-length variance minimization method to recover the true 2D projected center, resolving its dual-minima ambiguity via homography validation or a quasi-{RANSAC} fallback. Evaluated on synthetic and real-world datasets, our framework significantly outperforms state-of-the-art approaches. It reduces extrinsic estimation error and enables robust calibration across diverse sensors and target types, including natural circular objects. Our code will be publicly released for reproducibility.},
	number = {{arXiv}:2511.06611},
	publisher = {{arXiv}},
	author = {Jiang, Jiajun and Hu, Xiao and Liu, Wancheng and Jiang, Wei},
	urldate = {2026-02-02},
	date = {2025-11-10},
	eprinttype = {arxiv},
	eprint = {2511.06611 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	file = {Preprint PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\JD4DWKE8\\Jiang et al. - 2025 - On Accurate and Robust Estimation of 3D and 2D Circular Center Method and Application to Camera-Lid.pdf:application/pdf;Snapshot:C\:\\Users\\Gabriel\\Zotero\\storage\\Q5MI4SVY\\2511.html:text/html},
}

@article{wang_perspective_2025,
	title = {A Perspective Distortion Correction Method for Planar Imaging Based on Homography Mapping},
	volume = {25},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/25/6/1891},
	doi = {10.3390/s25061891},
	abstract = {In monocular vision measurement, a barrier to implementation is the perspective distortion caused by manufacturing errors in the imaging chip and non-...},
	number = {6},
	journaltitle = {Sensors},
	publisher = {publisher},
	author = {Wang, Chen and Ding, Yabin and Cui, Kai and Li, Jianhui and Xu, Qingpo and Mei, Jiangping},
	urldate = {2026-02-02},
	date = {2025-03-18},
	langid = {english},
	keywords = {homography mapping, monocular vision, perspective distortion, pixel equivalent, precision measurement},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\NWGZPL35\\Wang et al. - 2025 - A Perspective Distortion Correction Method for Planar Imaging Based on Homography Mapping.pdf:application/pdf},
}


@article{bahaghighat_estimation_2020,
	title = {Estimation of Wind Turbine Angular Velocity Remotely Found on Video Mining and Convolutional Neural Network},
	volume = {10},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/10/10/3544},
	doi = {10.3390/app10103544},
	abstract = {Today, energy issues are more important than ever. Because of the importance of environmental concerns, clean and renewable energies such as wind powe...},
	number = {10},
	journaltitle = {Applied Sciences},
	publisher = {publisher},
	author = {Bahaghighat, Mahdi and Xin, Qin and Motamedi, Seyed Ahmad and Zanjireh, Morteza Mohammadi and Vacavant, Antoine},
	urldate = {2026-02-03},
	date = {2020-05-20},
	langid = {english},
	keywords = {angular velocity, deep learning, image classification, machine vision, object detection, remote sensing, wind turbine, {WTCM}},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\9ZKCPX4A\\Bahaghighat et al. - 2020 - Estimation of Wind Turbine Angular Velocity Remotely Found on Video Mining and Convolutional Neural.pdf:application/pdf},
}

@article{natili_video-tachometer_2020,
	title = {Video-Tachometer Methodology for Wind Turbine Rotor Speed Measurement},
	volume = {20},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/24/7314},
	doi = {10.3390/s20247314},
	abstract = {The measurement of the rotational speed of rotating machinery is typically performed based on mechanical adherence; for example, in encoders. Neverthe...},
	number = {24},
	journaltitle = {Sensors},
	publisher = {publisher},
	author = {Natili, Francesco and Castellani, Francesco and Astolfi, Davide and Becchetti, Matteo},
	urldate = {2026-02-03},
	date = {2020-12-19},
	langid = {english},
	keywords = {correlation matrix, image processing, non-stationary machines, video tachometer, vision based measurement, wind turbines},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\X8URPFGC\\Natili et al. - 2020 - Video-Tachometer Methodology for Wind Turbine Rotor Speed Measurement.pdf:application/pdf},
}

@article{azevedo_event-based_2022,
	title = {Event-Based Angular Speed Measurement and Movement Monitoring},
	volume = {22},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/20/7963},
	doi = {10.3390/s22207963},
	abstract = {Computer vision techniques can monitor the rotational speed of rotating equipment or machines to understand their working conditions and prevent failu...},
	number = {20},
	journaltitle = {Sensors},
	publisher = {publisher},
	author = {Azevedo, George Oliveira de Araújo and Fernandes, Bruno José Torres and Silva, Leandro Honorato de Souza and Freire, Agostinho and Araújo, Rogério Pontes de and Cruz, Francisco},
	urldate = {2026-02-03},
	date = {2022-10-19},
	langid = {english},
	keywords = {angular speed, event-based vision, rotational measurement},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\RKAIP8JI\\Azevedo et al. - 2022 - Event-Based Angular Speed Measurement and Movement Monitoring.pdf:application/pdf},
}

@article{liang_real-time_2022,
	title = {Real-Time Marker-Based Tracking and Pose Estimation for a Rotating Object Using High-Speed Vision},
	volume = {34},
	issn = {1883-8049, 0915-3942},
	url = {https://www.fujipress.jp/jrm/rb/robot003400051063},
	doi = {10.20965/jrm.2022.p1063},
	abstract = {Object tracking and pose estimation have always been challenging tasks in robotics, particularly for rotating objects. Rotating objects move quickly and with complex pose variations. In this study, we introduce a marker-based tracking and pose estimation method for rotating objects using a high-speed vision system. The method can obtain pose information at frequencies greater than 500 Hz, and can still estimate the pose when parts of the markers are lost during tracking. A robot catching experiment shows that the accuracy and frequency of this system are capable of high-speed tracking tasks.},
	pages = {1063--1072},
	number = {5},
	journaltitle = {Journal of Robotics and Mechatronics},
	shortjournal = {{JRM}},
	author = {Liang, Xiao and Hirano, Masahiro and Yamakawa, Yuji and {Department of Mechanical Engineering, The University of Tokyo 4-6-1 Komaba, Meguro-ku, Tokyo 153-8505, Japan} and {Institute of Industrial Science, The University of Tokyo 4-6-1 Komaba, Meguro-ku, Tokyo 153-8505, Japan} and {Interfaculty Initiative in Information Studies, The University of Tokyo 4-6-1 Komaba, Meguro-ku, Tokyo 153-8505, Japan}},
	urldate = {2026-02-03},
	date = {2022-10-20},
	langid = {english},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\X8UH58GF\\Liang et al. - 2022 - Real-Time Marker-Based Tracking and Pose Estimation for a Rotating Object Using High-Speed Vision.pdf:application/pdf},
}


@article{pfeffer_advantages_2025,
	title = {Advantages of imperfect dice rolls over coin flips for random number generation},
	volume = {15},
	issn = {2045-2322},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC11976936/},
	doi = {10.1038/s41598-025-96492-8},
	abstract = {With an eye toward neural-inspired probabilistic computation, recent work has examined the development of true random number generators via stochastic devices. Typically, these devices are operated in a two-state regime to produce a sequence of binary outcomes (i.e., coin flips). However, there is no guarantee that stochastic devices will infallibly produce fair outputs and small deviations from a uniform distribution may have unwanted complications in applications. Using mathematical analysis, we contend that opting instead for a multi-state device (i.e., a dice roll) has benefits in these unfair paradigms. To demonstrate these benefits, we apply this framework to the analysis of a tunnel diode operated in a stochastic regime. In particular, interpreting the binary stochastic output of the tunnel diode as a multi-state die roll output also sees advantages in remaining closer to uniform. Overall, our approach provides a compelling argument for mathematical driven co-design and development of novel probabilistic computing devices and hardware.},
	pages = {11818},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Pfeffer, Douglas T. and Allemang, Christopher R. and Misra, Shashank and Severa, William and Smith, J. Darby},
	urldate = {2026-02-05},
	date = {2025-04-07},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\KTX792RQ\\Pfeffer et al. - 2025 - Advantages of imperfect dice rolls over coin flips for random number generation.pdf:application/pdf},
}

@article{campbell_dice_2022,
	title = {Dice Testing with the Running Chi-Square Distribution},
	url = {https://digitalcommons.wku.edu/seas_faculty_pubs/7},
	journaltitle = {{SEAS} Faculty Publications},
	author = {Campbell, Warren and Wimsatt, Hunter},
	date = {2022-07-01},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\5PTDWQ5W\\Campbell and Wimsatt - 2022 - Dice Testing with the Running Chi-Square Distribution.pdf:application/pdf;text/html Attachment:C\:\\Users\\Gabriel\\Zotero\\storage\\SVA8XTPH\\7.html:text/html},
}

@article{bassham_statistical_2010,
	title = {A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications},
	url = {https://www.nist.gov/publications/statistical-test-suite-random-and-pseudorandom-number-generators-cryptographic},
	abstract = {This paper discusses some aspects of selecting and testing random and pseudorandom number generators.},
	journaltitle = {{NIST}},
	publisher = {Lawrence E. Bassham, Andrew L. Rukhin, Juan Soto, James R. Nechvatal, Miles E. Smid, Stefan D. Leigh, M Levenson, M Vangel, Nathanael A. Heckert, D L. Banks},
	author = {Bassham, Lawrence E. and Rukhin, Andrew L. and Soto, Juan and Nechvatal, James R. and Smid, Miles E. and Leigh, Stefan D. and Levenson, M. and Vangel, M. and Heckert, Nathanael A. and Banks, D. L.},
	urldate = {2026-02-05},
	date = {2010-09-16},
	langid = {english},
	note = {Last Modified: 2017-02-19T20:02-05:00},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\Q26LM84I\\Bassham et al. - 2010 - A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Application.pdf:application/pdf},
}

@book{smith_essential_2011,
	title = {Essential Statistics, Regression, and Econometrics},
	url = {https://www.sciencedirect.com/book/monograph/9780123822215/essential-statistics-regression-and-econometrics?via=ihub%3D},
	doi = {10.1016/C2009-0-61163-6},
	abstract = {Essential Statistics, Regression, and Econometrics provides students with a readable, deep understanding of the key statistical topics they need to un...},
	publisher = {Academic Press},
	author = {Smith, Gary},
	urldate = {2026-02-05},
	date = {2011},
	langid = {english},
	note = {{ISBN}: 9780123822215},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\EL2567Z6\\Essential Statistics, Regression, and Econometrics.pdf:application/pdf;Snapshot:C\:\\Users\\Gabriel\\Zotero\\storage\\JZVPETLB\\essential-statistics-regression-and-econometrics.html:text/html},
}

@thesis{sani_comparative_2017,
	location = {Damaturu},
	title = {Comparative Analysis of Random Number Generators Using Monte Carlo Algorithm},
	doi = {10.13140/RG.2.2.36746.38081},
	abstract = {Random number generation is the art and science of deterministically generating sequence of random number that is difficult to distinguish from true random sequence. This thesis introduced the field of random number generation, where three random number generators implemented in c language are compared in terms of their uniform distribution, independence and speed. Each generator is described and its code presented. The tests used to evaluate the generators were simple ones. First, streams of random numbers generated were checked for uniform distribution by means of chi-square (goodness of fit) test. Next the numbers were checked for independence by means of a chi-square independent test (with contingency table). The code was then timed for a certain number of iterations. Finally, the results of
The generators are analyzed, and each generator is placed on a suitable application domain.},
	pagetotal = {57},
	institution = {{YOBE} {STATE} {UNIVERSITY}},
	type = {phdthesis},
	author = {Sani, Yusuf Auwal},
	date = {2017-11-01},
	file = {Full Text PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\K9FXZ4U3\\Sani - 2017 - Comparative Analysis of Random Number Generators Using Monte Carlo Algorithm.pdf:application/pdf},
}

@misc{martinez_biased_2016,
	title = {Biased Roulette Wheel: A Quantitative Trading Strategy Approach},
	url = {http://arxiv.org/abs/1609.09601},
	doi = {10.48550/arXiv.1609.09601},
	shorttitle = {Biased Roulette Wheel},
	abstract = {The purpose of this research paper it is to present a new approach in the framework of a biased roulette wheel. It is used the approach of a quantitative trading strategy, commonly used in quantitative finance, in order to assess the profitability of the strategy in the short term. The tools of backtesting and walk-forward optimization were used to achieve such task. The data has been generated from a real European roulette wheel from an on-line casino based in Riga, Latvia. It has been recorded 10,980 spins and sent to the computer through a voice-to-text software for further numerical analysis in R. It has been observed that the probabilities of occurrence of the numbers at the roulette wheel follows an Ornstein-Uhlenbeck process. Moreover, it is shown that a flat betting system against Kelly Criterion was more profitable in the short term.},
	number = {{arXiv}:1609.09601},
	publisher = {{arXiv}},
	author = {Martínez, Giancarlo Salirrosas},
	urldate = {2026-02-05},
	date = {2016-09-30},
	eprinttype = {arxiv},
	eprint = {1609.09601 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, Quantitative Finance - General Finance},
	file = {Preprint PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\UZNMU62X\\Martínez - 2016 - Biased Roulette Wheel A Quantitative Trading Strategy Approach.pdf:application/pdf;Snapshot:C\:\\Users\\Gabriel\\Zotero\\storage\\ZHQEQ8UG\\1609.html:text/html},
}

@article{abuhanna_roulette_2015,
	title = {Roulette: More than just a Chance},
	url = {https://oasis.library.unlv.edu/honors_theses/27},
	shorttitle = {Roulette},
	journaltitle = {Honors College Theses},
	author = {Abuhanna, David},
	date = {2015-05-01},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\A3T7D534\\Abuhanna - 2015 - Roulette More than just a Chance.pdf:application/pdf;text/html Attachment:C\:\\Users\\Gabriel\\Zotero\\storage\\GCZ3LAU4\\27.html:text/html},
}

@article{small_predicting_2012,
	title = {Predicting the outcome of roulette},
	volume = {22},
	issn = {1054-1500, 1089-7682},
	url = {http://arxiv.org/abs/1204.6412},
	doi = {10.1063/1.4753920},
	abstract = {There have been several popular reports of various groups exploiting the deterministic nature of the game of roulette for profit. Moreover, through its history the inherent determinism in the game of roulette has attracted the attention of many luminaries of chaos theory. In this paper we provide a short review of that history and then set out to determine to what extent that determinism can really be exploited for profit. To do this, we provide a very simple model for the motion of a roulette wheel and ball and demonstrate that knowledge of initial position, velocity and acceleration is sufficient to predict the outcome with adequate certainty to achieve a positive expected return. We describe two physically realisable systems to obtain this knowledge both incognito and \{{\textbackslash}em in situ\}. The first system relies only on a mechanical count of rotation of the ball and the wheel to measure the relevant parameters. By applying this techniques to a standard casino-grade European roulette wheel we demonstrate an expected return of at least 18\%, well above the -2.7\% expected of a random bet. With a more sophisticated, albeit more intrusive, system (mounting a digital camera above the wheel) we demonstrate a range of systematic and statistically significant biases which can be exploited to provide an improved guess of the outcome. Finally, our analysis demonstrates that even a very slight slant in the roulette table leads to a very pronounced bias which could be further exploited to substantially enhance returns.},
	pages = {033150},
	number = {3},
	journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Small, Michael and Tse, Chi Kong},
	urldate = {2026-02-06},
	date = {2012-09-01},
	eprinttype = {arxiv},
	eprint = {1204.6412 [nlin]},
	keywords = {Mathematics - History and Overview, Nonlinear Sciences - Chaotic Dynamics},
	file = {Preprint PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\FHY343GQ\\Small and Tse - 2012 - Predicting the outcome of roulette.pdf:application/pdf;Snapshot:C\:\\Users\\Gabriel\\Zotero\\storage\\YB5FQBTC\\1204.html:text/html},
}

@article{brambilla_algorithms_2023,
	title = {Algorithms for Vision-Based Quality Control of Circularly Symmetric Components},
	volume = {23},
	url = {https://doi.org/10.3390/s23052539},
	doi = {10.3390/s23052539},
	pages = {2539},
	number = {5},
	journaltitle = {Sensors},
	author = {Brambilla, Paolo and Conese, C. and Fabris, Davide and Pasinetti, S. and Nuzzi, C. and Sansoni, G.},
	date = {2023-02},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\Y9GJR2MP\\Brambilla et al. - 2023 - Algorithms for Vision-Based Quality Control of Circularly Symmetric Components.pdf:application/pdf},
}

@article{gadelmawla_measurement_2020,
	title = {Measurement and Inspection of Roundness Using Computer Vision},
	volume = {41},
	url = {https://doi.org/10.21608/BFEMU.2020.127536},
	doi = {10.21608/BFEMU.2020.127536},
	number = {4},
	journaltitle = {Bulletin of Faculty of Engineering Mansoura University},
	author = {Gadelmawla, Elamir and Khalifa, W. M. and Elewa, I. M.},
	date = {2020-12},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\GMZ8JE9U\\Gadelmawla et al. - 2020 - Measurement and Inspection of Roundness Using Computer Vision.pdf:application/pdf},
}

@inproceedings{xue_automatic_2023,
	title = {Automatic Inspection and Reading System of Pointer Instrument Based on Computer Vision},
	volume = {12604},
	url = {https://doi.org/10.1117/12.2660824},
	doi = {10.1117/12.2660824},
	booktitle = {Proceedings of {SPIE}},
	author = {Xue, Liming and Qin, Junping and Gao, Tong and Luo, Yu and Yang, Guangyuan},
	date = {2023-02},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\6UG6T6PN\\Xue et al. - 2023 - Automatic Inspection and Reading System of Pointer Instrument Based on Computer Vision.pdf:application/pdf},
}

@report{liquor_and_gaming_authority_of_manitoba_gaming_2018,
	title = {Gaming Integrity Standards: Roulette Wheels},
	url = {https://www.tistandards.ca/pdf/roulette_wheel_standards.pdf},
	institution = {Manitoba Liquor and Lotteries Corporation},
	author = {{Liquor and Gaming Authority of Manitoba}},
	date = {2018},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\2EDK8WJ4\\Liquor and Gaming Authority of Manitoba - 2018 - Gaming Integrity Standards Roulette Wheels.pdf:application/pdf},
}

@report{spillemyndigheden_testing_2020,
	title = {Testing Standards for Land-based Casino ({SCP}.01.05.{EN}.1.1)},
	url = {https://www.spillemyndigheden.dk/uploads/2020-09/SCP.01.05.EN_.1.1%20-%20Testing%20Standards%20for%20Land-based%20Casino%20-%20WT.pdf},
	institution = {Danish Gambling Authority},
	author = {{Spillemyndigheden}},
	date = {2020},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\GHY2RFNS\\Spillemyndigheden - 2020 - Testing Standards for Land-based Casino (SCP.01.05.EN.1.1).pdf:application/pdf},
}

@report{commonwealth_of_australia_australiannew_2018,
	title = {Australian/New Zealand Gaming Machine National Standard (Revision 11)},
	url = {https://www.cbs.sa.gov.au/documents/gaming-machine-national-standards.pdf},
	author = {{Commonwealth of Australia} and {New Zealand Government}},
	date = {2018},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\P8IJKZSX\\Commonwealth of Australia and New Zealand Government - 2018 - AustralianNew Zealand Gaming Machine National Standard (Revision 11).pdf:application/pdf},
}

@report{gaming_laboratories_international_gli-11_2016,
	title = {{GLI}-11: Gaming Devices},
	url = {https://gaminglabs.com/wp-content/uploads/2018/09/GLI-11-Gaming-Devices-V3-0.pdf},
	institution = {Gaming Laboratories International},
	author = {{Gaming Laboratories International}},
	date = {2016},
	file = {PDF:C\:\\Users\\Gabriel\\Zotero\\storage\\AF6JZFJL\\Gaming Laboratories International - 2016 - GLI-11 Gaming Devices.pdf:application/pdf},
}
