%=== CHAPTER TWO (2) ===
%=== Literature Review ===

\chapter{Literature Review}
\begin{spacing}{2.0}
%\setlength{\parskip}{0.2in}

\section{Computer Vision as a Measurement and Monitoring Tool}

% The field of computer vision exists to develop systems that allow computers to extract useful data from visual content, including images and video footage. Computer vision operates as an inverse problem which requires scientists to extract physical world properties from visual data that contains noise and missing information \cite{szeliski_computer_nodate, bradski_learning_2011}. The operation of vision-based systems depends on sensor noise, lighting changes, occlusions and restricted sensor resolution, which create fundamental uncertainty in their performance \cite{szeliski_computer_nodate, bradski_learning_2011}.

Computer vision serves engineering and inspection operations through its ability to perform measurements and monitoring tasks instead of its capacity for semantic interpretation. Camera-based systems provide automated non-contact physical process observation which produces repeatable objective results for quality assurance and calibration operations that require automated inspection, as manual observation becomes inconsistent and subjective \cite{szeliski_computer_nodate, gadelmawla_measurement_2020}. These systems operate at high speed to handle extensive data collection, which enables researchers to perform quantitative data evaluation.

Computer vision functions range from basic image processing operations to advanced image analysis and interpretation methods. The field of image processing deals with operations which accept images as input and produce images as output, but computer vision specialises in retrieving information and structural relationships and attributes from visual content \cite{the_math_works_inc_math_1991, szeliski_computer_nodate}. The stages in applied systems operate together to establish stable visual data which enables accurate measurement processes.

When utilising video as a data source, temporal sampling becomes a critical priority. For moving objects, measurement accuracy is heavily dependent on frame rate, exposure settings, and the management of motion blur. Robust vision systems must therefore account for both spatial and temporal effects to generate the precise, time-stamped observations required for subsequent analysis \cite{szeliski_computer_nodate, bradski_learning_2011}.

\section{Object Detection and Visual Tracking}

For video analysis, it is necessary to make computers capable of extracting and accurately locating objects and other visual details in still images and, if necessary, tracking them across consecutive frames \cite{fan_deep_2022, mandal_object_2020}. This ability is often discussed within the computer vision literature using the related concepts of object detection and tracking. Vision-based measurement systems are inherently affected by calibration accuracy, sensor noise, and perspective distortion. These factors have a considerable impact on the precision, complexity of the algorithms and robustness of the measurement system \cite{gholinavaz_robustness_2025, wang_perspective_2025, peng_high-precision_2025}.

In vision-based systems that support statistical analysis, inaccuracies introduced during visual localisation propagate into subsequent geometric interpretation and statistical inference, directly affecting the reliability of calibration and monitoring outcomes. A crucial step in the design of such systems is the choice between using a detection-only strategy and one which tracks visual features or objects over time \cite{fan_deep_2022, mandal_object_2020}.

Video analysis poses problems not present in still image analysis: motion blur, varying illumination, partial occlusion and fast object movement \cite{chen_design_2025}. This can often be achieved by using temporal models which take advantage of continuity between the individual frames \cite{mandal_object_2020}. The degree to which explicit tracking is required depends on the properties of the observed system in question \cite{fan_deep_2022, mandal_object_2020}. In constrained mechanical systems such as rotating wheels, turntables, and rotors, the shapes are rigid and the movement is in circles \cite{natili_video-tachometer_2020, liang_real-time_2022}. In constrained visual scenes these features have a significant impact on the trade-offs encountered.

Object detection in images is fundamentally different from tracking of objects in video streams \cite{fan_deep_2022, mandal_object_2020}. The distinction lies in the way the data is available to the algorithms. In the context of mechanically constrained, cyclic systems, it is crucial to understand how the paradigms in question affect system design. In the following sections, we examine the application of various detection approaches, from conventional image processing techniques to the more recent learning-based methods, considering these requirements \cite{afifah_yolov8_2026}.

\subsection{Object Detection versus Visual Tracking}

Both object detection and tracking are crucial components of video analysis. However, they deal with different aspects of video content. Object detection focuses on determining the location of objects within a static image. On the other hand, tracking follows the motion of identified objects over time. The task of object detection is essentially to localise objects in specific parts of a given picture, the location being one of the key pieces of information which is needed for object detection. Processing for each frame is typically done in isolation, which generates outputs such as the masks, bounding boxes or keypoints without making use of any temporal context in those particular processes \cite{szeliski_computer_nodate, fan_deep_2022}.

Traditional optical tracking relies on the presence of a feature in two successive images and is limited by the quality of the images and the availability of a feature in both images. Optical tracking also suffers from the presence of noise, in that a feature may be present in one image but not in another due to variations in illumination or other factors. The task is to track the position of an object through time, taking into account the position of the object in each frame of the sequence. This may involve relating the observations made in each image and using motion models to forecast where the object will be on the next frame \cite{fan_deep_2022}. Among traditional tracking techniques, Kalman filters, as well as particle filters and optical flow techniques, are frequently found. Conversely, contemporary tracking systems typically involve tracking by detection, combining per-frame detectors with temporal association mechanisms \cite{mandal_object_2020}.

In complex environments where there is no constraint and objects are subject to changes in appearance or occlusion through interaction with other objects, detection and tracking are vital. Currently, tracking-by-detection frameworks, for example, SORT and its variations, employ probabilistic motion models and data association algorithms to correlate detections between frames. This results in greater temporal stability and fewer missed object detections in scenes which are highly populated or in dynamic conditions \cite{mandal_object_2020}. However, these benefits come at the cost of increased algorithmic complexity and the introduction of new error modes, such as identity switches and cumulative drift \cite{fan_deep_2022}.

From the engineering viewpoint, the requirement for explicit state estimation is dependent on the characteristics of the system under observation. In rotational systems where the motion is constrained mechanically, the position of moving parts can be fixed, and their movements can be anticipated because the pattern of motion is predictable. In such systems, detections are defined relative to fixed spatial regions of interest corresponding to known geometric features, rather than through continuous object trajectory estimation. In many instances, frame-by-frame re-identification, coupled with precise time stamping and correct ordering of the output, can provide the temporal resolution required without the overhead of continuous tracking \cite{mandal_object_2020}.

Methods employing detection alone are simple and easy to understand. Since frame-by-frame detection takes place, error does not gradually accumulate over time, and thus failure can be directly attributed to certain conditions such as movement blur or light changes rather than to the system's internal state \cite{chen_design_2025, mandal_object_2020}. In calibration and monitoring processes, it is especially important that the output of the system is transparent. This is because the goal is to detect mechanical drift or a geometric deviation rather than tracking objects.

In fact, pipelines which merely detect events require the detector to be more robust and require more frequent sampling. Temporal smoothing techniques can be used to reduce this form of noise from occurring by introducing a form of delay between the measurement and the use of that measurement in the control process. While these restrictions can be considerable, they can be alleviated through higher frame rates and confidence thresholding \cite{gholinavaz_robustness_2025}. Alternatively, further analysis may be performed using geometric constraints, allowing tracking to be carried out less frequently without compromising the results.

Video analysis can be achieved through two different techniques, either by tracking visual objects or by detecting objects in images. In environments with lots of things happening at the same time, being able to track something is very important. However, in cases where parts of a machine move back and forth in a repeating cycle, it is often sufficient and advantageous to have the object detected \cite{chen_design_2025, mandal_object_2020}. This choice of methods is made clear in the next sections, where image processing techniques are used in the detection of objects. These techniques are based on traditional methods and also those which are learning-based \cite{fan_deep_2022, afifah_yolov8_2026}.

\subsection{Classical Image Processing Techniques}

In controlled environments where lighting, object appearance, and scene structure stay relatively unchanged, classical image processing techniques offer a set of deterministic, non-learning-based methods for image feature extraction \cite{bradski_learning_2011, han_reliable_2021}. In contrast to learning-based approaches, these methods are based on analytical models. These do not require learning from a dataset and are less computationally intensive and more comprehensible.

Template matching methods make use of a predefined image patch, called a template, to search through a larger image. It uses a similarity measure to compare the template with patches within the larger image. Due to their partial robustness to variations in global intensity and contrast, correlation-based similarity measures are often used, specifically normalised cross-correlation (NCC) \cite{briechle_template_2001}. The computational cost of normalised cross-correlation is reduced through efficient formulations, and this is achieved without a reduction in detection accuracy, thus allowing it to be used in real time \cite{briechle_template_2001}.

It is worth noting that template matching is sensitive to variations in the size of objects, as well as to variations in the objects' orientation and viewpoint. This happens because small template variations can affect the alignment of the template and the target \cite{han_reliable_2021}. This limitation has led researchers to investigate a multi-template strategy where separate templates for the varying orientations of the object are separately matched. Registration algorithms can be extended to account for rotation and scale variations; this is achieved by applying an FFT-based registration method before cross-correlation \cite{reddy_fft-based_1996}. However, these approaches increase the computational load and remain constrained by the discretisation of variations in pose.

Alongside spatial matching, another technique which is commonly used to simplify detection in such controlled environments is colour-based segmentation. The HSV model has the benefit of being able to separate the brightness of the light from the chromatic content, yielding more stable object detection results than thresholding based on RGB \cite{song_object_2025}. Efficient isolation of objects with distinctive colour can be achieved using a standard OpenCV pipeline involving morphological filtering and colour thresholds for hue, saturation and value \cite{song_object_2025, bradski_learning_2011}. This process is computationally inexpensive and easily understood, making it an appropriate choice for real-time vision systems and those which are embedded.

Traditional processing of images has the benefits of simplicity of design, transparency and the lack of any necessity for training examples \cite{bradski_learning_2011, han_reliable_2021}. Low-complexity estimators have several characteristics that make them useful for applications with restricted computational power or with predictable system conditions. Their main limitation is their susceptibility to changes in the environment, including variations in lighting, objects blocking the camera's view and movements in the scene which were not taken into consideration \cite{han_reliable_2021}. The effectiveness of these methods is heavily dependent on acquiring the data under strict controls and proper parameter adjustment.

\subsection{Learning-Based Detection Methods}

Modern object detection is commonly divided into two-stage and single-stage pipelines. Generally, single-stage detectors, like SSD and YOLO, classify objects directly without preliminary region-proposal steps. However, these direct approaches typically sacrifice some level of accuracy for the sake of speed, especially in more complex scenarios. In single-stage detectors, class probabilities and bounding box coordinates are output directly in a single forward pass. This speed-accuracy trade-off is evidently shown through comparative benchmarking with visual corruption. Clean images are typically where single-stage models like YOLO will excel, but severe corruption can cause two-stage approaches to be more stable, which is a trade-off that can be influenced by the choice of training strategy and data augmentation \cite{gholinavaz_robustness_2025}.

Single-stage detectors, such as SSD, have shown that object detection can be achieved in real-time without the use of pre-processed object proposals. This is done by predicting class probabilities and bounding box offsets directly over multiple-scale feature maps. This multi-scale prediction technique is especially useful when objects are at varying sizes in a scene because the model's performance is improved when it has access to data from various resolutions \cite{liu_ssd_2016}.

% Within single-stage detection, the YOLO family is notable for prioritising the balancing of localisation precision with processing speed, which results in sufficient object localisation accuracy in real-world systems. Current developments in the YOLO project, particularly in versions YOLOv8 and above, represent a shift towards the use of network architectures that increase small object detection capabilities and improve the stability of optimisation without compromising real-time processing speeds \cite{afifah_yolov8_2026}. A YOLOv8-style model can be considered to be composed of three main components: input pre-processing, a backbone, and prediction components. The prediction components comprise a neck for multi-scale feature fusion and a head for final object prediction. The pre-processing stage typically incorporates sophisticated data augmentation techniques, such as mosaicing or tile-and-blend-style image mixing, to improve the network’s generalisation capabilities. Pre-processing can also take place at this point to improve the neural network's generalisation capabilities. In models such as YOLOv8, the backbone extracts hierarchical features, typically through the use of CSP-style designs that incorporate a C2f module. The neck of the model fuses multi-scale features according to FPN/PAN principles. Ultimately, the network's head is responsible for producing output related to classification and the bounding box's location. YOLOv8 uses a decoupled head which separates the tasks of classification and regression in order to reduce dependence on the hand tuning of parameters and to make it easier to adapt to new data sets \cite{afifah_yolov8_2026}.

Within single-stage detection, the YOLO family is notable for prioritising the balancing of localisation precision with processing speed, which results in sufficient object localisation accuracy in real-world systems. Current developments in the YOLO project, particularly in versions YOLOv8 and above, represent a shift towards the use of network architectures that increase small object detection capabilities and improve the stability of optimisation without compromising real-time processing speeds \cite{afifah_yolov8_2026}. A YOLOv8-style detector can be described at a high level as a backbone--neck--head pipeline. The backbone learns hierarchical visual features, while the neck performs multi-scale feature fusion to support localisation at different object sizes. The prediction head then outputs class probabilities and bounding box regression parameters in a single forward pass. In practice, performance in real-world scenes is strongly influenced by the training strategy and data augmentation, which can improve generalisation to blur, glare, and illumination variability \cite{afifah_yolov8_2026}.

One of the major advantages of YOLOv8-style detectors is that they are capable of real-time processing. This is a key reason why they are of use in the monitoring of high frame rates. Studies of rotating machinery inspections indicate that the YOLOv8 model can be modified to make a portable system by combining motion stabilisation techniques with two other optimisation methods: the use of faster neural network algorithms and the use of faster computer chips. Using temporal compensation, an edge-based system detects rotating machinery, eliminating inter-frame motion effects with optical flow. It uses a customised version of YOLO that incorporates depthwise separable convolution and feature fusion, and this setup provides a real-time capability on the platform. This type of design is particularly relevant in the capture of roulette-style images, where fast motion, camera vibration and the effect of blur can otherwise lower the detection accuracy and lead to missed targets \cite{chen_design_2025}.

A significant challenge in automatically recording roulette outcomes lies in the small scale of the target objects, specifically the roulette ball or winning marker. This can be a problem because it can occupy a very small area on the image, especially if the camera is not positioned closely to the game or the entire roulette layout is not visible. Small objects are particularly affected by downsampling and the loss of feature detail in object detection tasks using YOLOv8. This means that such tasks need better combining of data from different feature scales and appropriate data augmentations \cite{afifah_yolov8_2026,yao_hp-yolov8_2024}. Such approaches concentrate on small objects by employing certain architectural adjustments intended to maintain small object features. For example, HP-YOLOv8 introduces modifications to (a) feature extraction modules, (b) attention-based feature fusion, and (c) bounding-box regression loss design to better represent small targets under clutter and overlap. While this research does not aim to replicate the specific modules of HP-YOLOv8, it adopts the underlying principle to justify why roulette-ball detection benefits from (i) stronger multi-scale features, (ii) attention/feature fusion strategies, and (iii) loss/assignment choices that do not collapse when the object is tiny or partially occluded \cite{yao_hp-yolov8_2024}. 

Roulette images often contain motion blur, reflections, changing lighting conditions and sometimes partial occlusion. As a result, data augmentation should be considered at the design stage for this kind of object detection system. Experiments in robustness benchmarking have shown that models trained and tested under abnormalities (e.g., blur, fog-like effects, Gaussian or salt-and-pepper noise) exhibit clear differences in how the performance degrades and that the "best" model can change depending on whether the operating environment is clean or visually corrupted \cite{gholinavaz_robustness_2025}. These results highlight a trade-off that is of importance: robustness typically requires additional computational requirements (possibly more compute, more augmentation, careful benchmarking). This is in contrast to lightweight variants, which can sometimes perform better under corruption despite achieving lower peak accuracy on clean images \cite{gholinavaz_robustness_2025}. In the context of a roulette vision pipeline, this allows the image augmentation to be considered as a controlled variable in the design, aligned with failure modes like blur, glare and low light.

These algorithms should be tested using performance criteria appropriate for a high-speed rotational measurement context as well as standard measures of accuracy. In this roulette detection problem, we wish to ensure that the system is able to continuously and correctly identify the ball’s location across successive frames and maintain accurate position throughout a sequence of images and that inference latency is consistent, ensuring that predictions remain synchronised with the physical system. Studies of rotational machinery show that preprocessing, including compensation for motion, may be necessary when dealing with camera shake or the target moving quickly \cite{chen_design_2025}. Research on the detection of small objects indicates that it is advantageous to use a network architecture that can handle objects at various scales \cite{yao_hp-yolov8_2024}. While the analysis lends weight to selecting a YOLOv8-style detector as a strong baseline for the identification of roulette outcomes, it also suggests that improving robustness (through the use of data augmentations and stochastic regularisation as well as model tuning) is at the cost of increased complexity and experimentation time \cite{gholinavaz_robustness_2025, chen_design_2025}.

\section{Geometric Calibration and Spatial Normalisation}

Geometric calibration's role in a vision-based measurement pipeline is to convert observed images into a constant reference framework (or space) where all angular, spatial, and positional displacements have the same physical dimensions \cite{wang_perspective_2025, peng_high-precision_2025}. In other words, pixel coordinates in a camera are camera-specific; the same object location will produce different $(u,v)$ locations depending upon camera orientation, focal length, distortion, and depth. Therefore, using uncorrected pixel coordinates will cause systematic error and variable time-related bias due to camera motion, vibration, etc., resulting in inconsistent measurements throughout recordings \cite{wang_perspective_2025, hinderer_groundgazer_2025}.

\subsection{Camera Perspective Distortion and the Limits of Pixel Coordinates}

Perspective projection causes equal real-world displacements to be represented differently within the image as a function of where those displacements occur within the field of view. When viewing planar scenes at an angle, straight lines and shapes become skewed or non-uniformly scaled, causing inaccurate measurements when not compensated by geometry correction methods such as homography mapping. Wang et al. discuss a new perspective distortion correction technique for planar imaging applications based on homography mapping. They emphasise that pixel-level measurement accuracy is dependent upon compensation for the projective deformation caused by the specific imaging configuration \cite{wang_perspective_2025}.

Accurate calibration is equally important for reliable geometric corrections. In industrial visual measurement applications, large fields of view and inaccuracies in the calibration process may significantly affect parameter estimation. Peng et al. propose a calibration improvement for industrial applications through compensation of eccentricities of concentric circle targets and explicit modelling of calibration board deviation parameters in order to decrease downstream transformation errors and increase parameter fidelity \cite{peng_high-precision_2025}.

\subsection{Homography and Projective Transformations}

Given that the scene structure relevant to the measurement can be modelled as planar, a projective transformation (homography) can map image plane points to a desired planar coordinate system. Homographies are determined from the corresponding reference points (such as corners or centres of fiducials) and represent a principled method of normalising measurements to a common spatial frame. Practically, it permits measurements to be compared across sessions, cameras or small pose variations by representing detected features in the same geometric coordinate system \cite{wang_perspective_2025}.

An important constraint is that the reference correspondences used to determine the above transformations be both robust and accurate. Concentric-circle fiducials are attractive due to their rotational invariance and reliable detectability. Wei et al. proposed an iterative calibration approach based on a concentric circle grid using geometric invariants to increase the robustness of feature localisation during calibration \cite{wei_iterative_2024}. For applications using circular fiducial marks, Jiang et al. further demonstrated that naive 2D ellipse-centre estimation can be ambiguous and presented a method to accurately recover 2D projected centre coordinates and robust 3D–2D correspondences, increasing the dependability of camera–LiDAR (and more generally sensor) calibration \cite{jiang_accurate_2025}. These insights are especially relevant in systems that estimate homographies from elliptical contours, such as the outer rim of a wheel.

\subsection{Mapping Oblique Views to Top-Down Representations}

Spatial normalisation is typically performed by converting oblique camera views to a top-down (bird’s eye) representation, allowing for measurement of displacements in a ground-plane coordinate system. The homography transforms detected image features onto a planar world model and facilitates a more direct interpretation of displacements and relative position. Hinderer et al. demonstrated that a camera observing a known planar pattern can be used to estimate position and direction at high precision by utilising the reference planar structure, illustrating the significance of a well-defined planar frame for consistent spatial inference \cite{hinderer_groundgazer_2025}.

To summarise, geometric calibration and spatial normalisation remove dependency on viewpoint and camera configuration by (i) correcting perspective distortions, (ii) substituting raw pixel coordinates with a consistent planar coordinate system via homographies, and (iii) providing accurate and robust reference correspondences to estimate the above mappings. This establishes the basis for consistent measurement over time and enables equivalent comparison of results across different recordings and experimental conditions \cite{wang_perspective_2025,peng_high-precision_2025,wei_iterative_2024,jiang_accurate_2025,hinderer_groundgazer_2025}.

\section{Vision-Based Analysis of Rotational Systems}

Computer vision systems need to be adapted to take into account the particularities of rotational systems, including their geometrical and temporal specificities \cite{natili_video-tachometer_2020, azevedo_event-based_2022}. Unlike linear motion, rotational systems have repetitive spatial layouts and angular symmetries; therefore, they enable techniques such as angular segmentation and cyclic geometry-based mapping. These characteristics will also allow for the application of polar transformation and radial overlay to simplify the tracking task or to stabilise the rotational features.

An effective method to visually calibrate rotating systems consists of identifying and tracking reference markers or coloured sectors. Marker-based methods, based on high-speed vision systems, provide very precise pose estimations of fast-moving rotors, thanks to the combination of motion prediction and region-specific segmentation \cite{liang_real-time_2022}. Coloured markers, placed on the wheel surface, serve both as calibration anchors and outcome identifiers, especially when designed to remain visible under varying lighting conditions. Such methods are particularly useful for roulette-style wheels, where repeated sectors and circular geometry require sub-frame temporal accuracy and stable radial alignment.

Numerous studies show how the cyclic motion of rotating elements facilitates the temporally sequential ordering of events. As an example, Natili et al. track wind turbine blades by relating each video frame to a reference image to obtain a virtual tachometer signal which represents the rotor's angular speed over time \cite{natili_video-tachometer_2020}. Thanks to the periodic nature of the blade passage, the robust frequency estimation is possible through spectrogram analysis even in the presence of wind-induced variability. In similar ways, Bahaghighat et al. extract the rotor speed from video using optical flow and deep learning, effectively handling low frame rates and compressed footage, highlighting the utility of temporal models in real-world conditions \cite{bahaghighat_estimation_2020}.

Rotational systems also pose unique visual challenges. Motion blur is one of the most significant problems in the case where the rotors rotate faster than the frame rate allows for a clear image capture. This problem is particularly significant in high-speed applications, as demonstrated by Azevedo et al., who use event-based cameras to bypass the conventional blur problem by asynchronously acquiring pixel-level intensity changes \cite{azevedo_event-based_2022}. Another major challenge is specular reflection, commonly found on shiny or metallic surfaces, which can impair feature detection. Techniques, such as controlled lighting or image enhancement during training, can be used to reduce the influence of this phenomenon.

Roulette-style wheels serve as valuable case studies, given their cyclical arrangement and their fixed reference points. The alternation of colours, the repetition of the sectors and the presence of a single indicator (e.g., a ball or a pointer) create a highly structured environment for the vision analysis. Furthermore, these systems are very suitable for angular segmentation and polar mapping, which transform the circular motion into linear representations for easier calculation.

Overall, rotational systems offer exploitable structure but require specialised vision approaches to handle motion blur, reflective noise and cyclic sequencing. The vision-based calibration and monitoring of such systems exploit these characteristics to accurately monitor outcomes and assess system health.

\section{Statistical Modelling of Randomness and Mechanical Bias}

This area of study provides the foundational statistical frameworks to examine mechanical randomness generation in terms of "fairness", "uniformity", and "bias" through statistical modelling of the randomness generation mechanism. In addition to these statistical concepts being useful for determining whether an observed output could have been generated randomly, they provide a basis to determine if any observed outputs could have been generated by mechanical imperfections, drift, or both.

\subsection{Uniformity and Independence Assumptions}

Physical random number generators, such as mechanical devices like dice or roulette wheels, are typically modelled as having 'independent and identically distributed' (i.i.d.) trial outcomes, such that the probability distribution of the outcome for each trial is assumed to be constant and independent of the preceding trials.

Pfeffer et al. describe a mathematical framework for comparison of coins and dice in stochastic computation that demonstrates that when small biases are introduced in multi-outcome systems (dice), they will tend to retain their uniform characteristics better than binary systems. They highlight the importance of retaining uniformity in practical systems and that even very small deviations in uniformity may be magnified into significant imbalances based on statistical principles \cite{pfeffer_advantages_2025}. Although the original study is situated in the context of stochastic computation, its insights are transferable to physical systems where minor imperfections, such as slight shape distortions, may similarly distort uniformity.

Smith establishes a theoretical and conceptual framework for fairness in physical systems by defining a fair roulette wheel as one in which all possible outcomes are equal in probability and independent. He references historical analyses of actual roulette wheels and their mechanical flaws resulting in predictable biases. Smith also emphasises the utility of examining the empirical outcome frequency data to identify violations of fairness \cite{smith_essential_2011}.

Campbell and Wimsatt performed experiments using twenty-sided dice (d20s) and demonstrated how mechanical irregularities violated the expectation of uniform distribution in their d20s. They utilised a running chi-square test to track the degree of deviation from the expected frequencies during the course of thousands of trials and illustrated that the slope of the test statistic represents the degree of unfairness. The 'running' form of the test differs from the conventional version by recalculating the statistic incrementally after each trial, offering a visual timeline of how bias may develop. Their work also touches on the effects of the rolling method (manual vs. automated), which can affect independence between trials \cite{campbell_dice_2022}.

Martínez emphasised the importance of analysing outcome frequencies using his large-scale roulette experiment. Martínez collected 10,980 spins and created a probability mass function to evaluate the degree of deviation from expected uniform probabilities. The observed outcomes were analysed as a stochastic process and indicated consistent and measurable deviations from the assumption of i.i.d. \cite{martinez_biased_2016}.

Collectively, these authors establish that fairness is defined as the simultaneous presence of uniformity among the outcomes and independence between trials. Uniformity may be evaluated using comparisons of the observed frequency of the outcomes with the theoretically predicted frequency, whereas independence may be established through statistical evaluations of serial dependence or streaks.

\subsection{Statistical Tests for Mechanical Bias and Drift}

Mechanical bias and drift refer to the persistent or temporal changes in the deviation of a system's behaviour from expected random behaviour due to mechanical defects within the system. Statistical techniques can be employed to quantify and detect such bias and drift through comparison of the observed frequency distributions of the outcomes with those derived from theoretical models.

One common statistical technique for assessing the uniformity of the outcomes of a mechanical randomisation system is the chi-squared goodness-of-fit test. Campbell and Wimsatt extended the application of the chi-squared test by developing the running chi-square method, which evaluates the test statistic after each successive trial and plots it against the number of trials. A flat plot indicates no bias, whereas an increasing plot indicates an accumulation of bias. Campbell and Wimsatt found that at less than 300 trials, dice with strong bias may still appear fair and thus emphasise the need for sufficiently large sample sizes to accurately detect bias \cite{campbell_dice_2022}.

The National Institute of Standards and Technology (NIST) developed the Statistical Test Suite for Random Number Generators, which contains the runs test and several other tests that utilise frequency analysis to evaluate the randomness of binary and multi-state systems. The runs test examines the frequency and length of sequences of the same values to determine the presence of dependent trials. The suite contains additional frequency-based tests (e.g., monobit, block frequency) to evaluate the uniformity of binary and multi-state systems \cite{bassham_statistical_2010}.

Martínez utilised the chi-squared test in his analysis of the roulette experiment to detect deviations from uniformity and modelled the changing probability of each outcome as an Ornstein-Uhlenbeck process, a type of stochastic model commonly used to model drift. Martínez found that detecting small biases requires a minimum of 10,000 spins, which again emphasises the importance of sufficient statistical power and sample size in detecting mechanical bias \cite{martinez_biased_2016}. In practice, this raises important considerations for live monitoring systems, which may require automation to achieve such sample volumes within a feasible timeframe.

Sani's work complements the above applied works through a comparative examination of statistical tests and Monte Carlo simulations, finding that the sensitivity of tests to bias increases with both sample size and effect size \cite{sani_comparative_2017}.

Overall, statistical modelling of mechanical randomness combines theoretical models of mechanical randomness (i.e., i.i.d. and uniformity) with applied statistical tests (chi-squared and runs tests) to measure the degree of fairness and drift of mechanical randomisation systems. These tools are necessary to verify whether a mechanical randomisation system behaves ideally statistically or exhibits some form of degradation or design flaw. In this project, they also serve as the analytical backbone of the proposed calibration framework, guiding both offline analysis and real-time monitoring.

\section{Empirical Evidence of Mechanical Bias in Rotational Systems}

% The roulette wheel is presumed to generate random results when spun due to equal physical probability in each numbered pocket. Experimental investigations have shown however, that small mechanical faults or changes in environmental conditions can cause the apparent randomness to become distorted through various forms of bias. While the degree of distortion may be minimal, it is possible to measure statistically significant differences, and in many instances, be exploitable.

% One of the first investigations into the distortion of randomness in a roulette wheel was done by Small and Tse. They utilized both a physics based model and an actual casino style wheel to demonstrate that small tilts (about 0.2°) of a roulette wheel could result in a distribution of balls landings that significantly deviates from the theoretically uniform distribution of the 38 pockets. The authors demonstrated that although the distortion created by small mechanical errors was minuscule, they could be leveraged to create a positive expected return of up to 18\%. As a result their investigation quantitatively demonstrated that the outcomes of a roulette game were determined not by pure chance, but by deterministic physical processes that are highly dependent upon physical parameters such as spin speed, the trajectory of the ball, and the angle of inclination of the table \cite{small_predicting_2012}.

% Abuhanna also investigated real world results of a roulette game. He collected data on the results of numerous roulette games under normal operational conditions. His results showed a statistically significant relationship between the location from which the ball was launched and where it came to rest, thus he was able to demonstrate that there existed predictable patterns created by either procedural influences or by the variability of the forces applied during spinning that resulted from the use of human operators. Although the mechanical components of the wheel did not change, Abuhanna's results showed that the environmental influence of human operators caused a measurable effect on the fairness of the statistical results \cite{abuhanna_roulette_2015}.

% Martínez has performed a large scale investigation utilizing 10,980 spins of an online live European Roulette Wheel that was operated out of Riga, Latvia. His statistical analysis demonstrated that several numbers were occurring with probabilities significantly greater than the theoretical 1/37 (or 2.7\%) probability. Specifically, Martínez reported that number nine was occurring at a frequency of 3.22\% within his sample, a difference far greater than one might expect simply by random variation \cite{martinez_biased_2016}. It appears that Martínez's results indicate either long term drift or a sustained mechanical imbalance in the wheel possibly due to wear of the mechanical components, inconsistent friction, or an axial misalignment. It is important to note that while the entire wheel appeared to pass a Chi-Square test for statistical bias, Martínez reported that using the anomalies found in his results, he was able to create consistent short-term returns on investment for select betting strategies. This demonstrates that while the wheel does not appear to exhibit bias over time, small deviations from perfect randomness can still have practical implications for skilled or attentive players \cite{martinez_biased_2016}.

% Collectively, the results of these studies provide strong empirical evidence that physical roulette wheels are capable of exhibiting measurable deviations from ideal randomness as a result of mechanical bias, procedural influences, or mechanical wear. Such deviations may occur slowly over time; thus requiring continued evaluation. In the absence of ongoing monitoring, whether through statistical methods or sensors; such imperfections will remain undetected and potentially lead to exploitation opportunities or non-compliance with gaming regulations. Therefore, a necessary development in ensuring the fairness and integrity of mechanical rotational systems, is the implementation of automated 

Roulette wheels are commonly modelled as ideal randomisers in which each pocket has equal probability and outcomes are independent across trials \cite{smith_essential_2011}. Empirical investigations have shown, however, that small mechanical faults and operational conditions can introduce measurable deviations from uniform and independent behaviour \cite{small_predicting_2012, abuhanna_roulette_2015, martinez_biased_2016}. While such deviations may be low in magnitude, sufficiently large datasets can reveal statistically significant structure in outcome frequencies, motivating automated monitoring approaches for integrity assurance \cite{campbell_dice_2022, martinez_biased_2016}.

Small and Tse combined a physics-based model with experiments on a casino-style wheel to show that small tilts (approximately $0.2^\circ$) can yield outcome distributions that deviate from the theoretically uniform distribution across pockets. Their analysis illustrates that roulette outcomes are governed by deterministic physical dynamics that are sensitive to mechanical parameters such as wheel inclination, spin conditions, and ball trajectory \cite{small_predicting_2012}. From a monitoring perspective, this demonstrates that minor geometric deviations can have measurable statistical effects.

Abuhanna analysed roulette outcomes collected under operational conditions and reported a statistically significant relationship between the ball launch location and the eventual resting position. This suggests that procedural variation (e.g., operator-dependent launch dynamics) can introduce non-random structure even when the wheel hardware itself is unchanged, highlighting that fairness is influenced by both mechanical and operational factors \cite{abuhanna_roulette_2015}.

Martínez conducted a large-scale analysis of 10,980 spins of an online live European roulette wheel and reported that some numbers occurred more frequently than predicted under a uniform $1/37$ model. Although a global chi-squared test may not always flag the wheel as biased, persistent local deviations can still be practically meaningful and may indicate long-term imbalance or drift due to wear, friction variation, or misalignment \cite{martinez_biased_2016}. This reinforces the importance of both adequate sample sizes and monitoring methods capable of detecting low-magnitude deviations.

Collectively, these studies provide evidence that roulette-style systems can exhibit measurable departures from ideal randomness due to mechanical imperfections, operational procedures, or gradual wear. As such deviations may emerge slowly over time, periodic manual inspection can be insufficient to provide continuous assurance. This motivates automated monitoring frameworks that combine reliable measurement (e.g., vision-based localisation and geometric normalisation) with statistical testing to detect and track deviations as they develop.

\section{Calibration Standards and Regulatory Context}

The mechanical accuracy and statistical fairness of gaming equipment, particularly those involving rotational systems such as roulette wheels, are governed by regulatory frameworks that specify permissible mechanical tolerances and mandate regular inspection procedures \cite{liquor_and_gaming_authority_of_manitoba_gaming_2018, spillemyndigheden_testing_2020, gaming_laboratories_international_gli-11_2016}. These regulations define the criteria used to assess whether gaming equipment remains mechanically accurate and fair throughout operation. However, the methods employed to verify regulatory compliance continue to rely predominantly on manual inspection practices, resulting in a discrepancy between the precision required by regulation and the technological capability currently used to assess that precision \cite{gaming_laboratories_international_gli-11_2016, gadelmawla_measurement_2020}.

\subsection{Existing Standards and Manual Inspection Practices}

The Manitoba Gaming and Liquor Authority defines specific requirements for the manufacturing and maintenance of roulette wheels. Specifically, the authority defines construction tolerances for roulette wheels, including requirements for wheel balance, alignment, and pocket uniformity, and provides procedures for inspecting whether the equipment remains mechanically accurate. Additionally, the authority specifies that mechanical deviation from the approved specifications should be detected during the course of the inspections \cite{liquor_and_gaming_authority_of_manitoba_gaming_2018}. Similarly, European countries, specifically Denmark, have established similar testing standards for land-based casinos, emphasising geometric consistency and mechanical integrity through regular inspections \cite{spillemyndigheden_testing_2020}. A comparable principle exists within Australia/New Zealand in the form of the Australian/NZ Gaming Machine National Standard, which outlines international agreement on precision requirements for roulette wheels \cite{commonwealth_of_australia_australiannew_2018}.

Similarly, the GLI-11 standard for gaming devices details mechanical and construction requirements for roulette wheels and associated gaming equipment. Compliance with the standard is verified primarily through visual inspection and functional testing, as opposed to through the use of automated measuring equipment \cite{gaming_laboratories_international_gli-11_2016}.

Although regulatory frameworks emphasise mechanical precision, compliance is still determined primarily through manual visual inspection and contact-based measurement. Roulette wheel operators assess the levelness, deformation and wear of their roulette wheels through subjective observation combined with mechanical gauges. Although these methods are sufficient to meet regulatory minimums, they provide significant limitations to the number of inspections that may be performed, the ability to repeat the inspections and the ability to detect small geometric deviations.

\subsection{Limitations of Non-Automated Approaches}

The application of manual inspection methods to the precision calibration of rotational systems exhibits several measurable limitations \cite{brambilla_algorithms_2023, gadelmawla_measurement_2020}. Variability in the measurement made by the operator results in inconsistent measurements being taken throughout the day and shift, while the throughput of the manual method limits the statistical confidence that can be obtained in identifying low-magnitude defects in circularly symmetric components \cite{brambilla_algorithms_2023}. Environmental factors also adversely affect the reliability of the manual inspection method, including variations in light, reflections and surface glare resulting in systematic error that is difficult to manage through manual inspection, particularly with respect to polished or reflective surfaces \cite{xue_automatic_2023}.

Studies comparing manual inspection methods to calibrated commercial roundness testers have highlighted these limitations. For example, Gadelmawla et al. found that manual inspection and uncalibrated vision-based inspection methods could result in errors of ±7.22\% relative to a calibrated commercial roundness tester \cite{gadelmawla_measurement_2020}. This study demonstrated the inadequacy of subjective visual assessment and the need for a metrologically valid method in any inspection system designed to support regulatory compliance.

\subsection{Opportunities for Vision-Based Calibration}

Advances in computer vision have recently identified potential solutions to the limitations of manual inspection while continuing to align with regulatory objectives \cite{azevedo_event-based_2022, brambilla_algorithms_2023, gadelmawla_measurement_2020}. Vision-based rotational monitoring using either vision-based or event-driven sensing has resulted in mean absolute errors less than 0.2\%. Thus, continuous verification of rotational consistency and early detection of mechanical degradation have been achieved \cite{azevedo_event-based_2022}, methods that are impractical to achieve through manual observation alone.

Vision-based geometric inspection of circularly symmetric components has resulted in defect detection accuracies greater than 99\% under controlled conditions \cite{brambilla_algorithms_2023}. The image-based roundness measurement technique, when validated, compares favourably to commercial roundness testers while providing non-contact, multi-feature inspection \cite{gadelmawla_measurement_2020}. The inspection of roulette wheel rims, pocket spacing and deformation can be accomplished using these capabilities.

In summary, existing regulatory standards require high levels of mechanical precision, while current inspection practices for gaming equipment remain largely manual and susceptible to operator variability, environmental conditions, and limited measurement resolution. Therefore, the literature indicates a clear potential for the development of vision-based calibration tools to enhance the regulatory framework by improving the repeatability of measurement, the sensitivity of measurement and the capability of inspecting gaming equipment at higher rates of throughput.

\section{Literature Synthesis and Research Gap}

The literature establishes three complementary foundations relevant to the monitoring of roulette-type rotational systems. Computer vision enables the localisation of small targets in video streams using either deterministic image processing techniques or learning-based detectors, with modern YOLO-type models demonstrating improved robustness to blur, glare and illumination variability when appropriately trained and evaluated \cite{gholinavaz_robustness_2025, afifah_yolov8_2026}. Geometric calibration and spatial normalisation provide the mathematical framework required to transform image observations into a consistent planar reference frame, reducing sensitivity to viewpoint variation and enabling comparability across recording sessions \cite{wang_perspective_2025, wei_iterative_2024, jiang_accurate_2025}. Statistical modelling frameworks, in turn, define fairness in terms of uniformity and independence and provide hypothesis tests capable of detecting deviations and drift when sufficient sample data is available \cite{bassham_statistical_2010, campbell_dice_2022, martinez_biased_2016}.

Although significant advances have been made in each area, existing research is generally disjointed among the areas. Recognition studies are commonly benchmarked against recognition metrics (e.g., precision/recall or mAP). However, such evaluations rarely consider whether detections constitute metrologically valid measurements once projective transformations, calibration uncertainty, and temporal sampling effects are taken into account \cite{szeliski_computer_nodate}. Calibration studies generally assume laboratory-style targets and/or controlled imaging configurations, whereas roulette-type systems introduce oblique views, cyclic geometry, reflective surfaces and motion blur, which can compromise correspondence accuracy and render spatial mappings unstable \cite{azevedo_event-based_2022, jiang_accurate_2025}. On the other hand, empirical bias studies have demonstrated that measurable deviations can occur due to tilt, procedural variation, or wear; however, many of these studies rely on the assumption that outcome measurements are readily available without providing detail regarding the automated measurement pipeline necessary to generate reliable and time-stamped observations \cite{small_predicting_2012, abuhanna_roulette_2015, martinez_biased_2016}. As a result, the literature does not currently provide a clear, end-to-end framework that ensures detected outcomes are both geometrically valid and statistically interpretable under real operational conditions. Regulatory standards emphasise mechanical precision and periodic inspection; however, the primary assessment procedures remain manual and therefore lack repeatability, sampling rate and sensitivity to low-magnitude drift \cite{liquor_and_gaming_authority_of_manitoba_gaming_2018, spillemyndigheden_testing_2020, gaming_laboratories_international_gli-11_2016}.

This dissertation addresses this gap by examining an integrated, low-cost vision-based measurement and monitoring pipeline for roulette-type rotational systems. The proposed approach combines (1) robust localisation of key visual indicators, (2) geometric normalisation via homography-based mapping derived from circular and elliptical correspondences, and (3) statistically grounded monitoring criteria to assess whether observed outcomes remain consistent with ideal behaviour over time. The contribution is positioned as a practical framework for repeatable measurement and early detection of mechanical deviation using accessible sensing, aligned with the monitoring needs implied by empirical bias evidence and regulatory objectives, rather than as a replacement for certified metrology equipment.


%=== END OF CHAPTER TWO ===
\end{spacing}
\newpage
