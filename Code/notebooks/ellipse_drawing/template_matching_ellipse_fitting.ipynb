{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e91d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import csv\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils.file_dialog_utils import pick_video_cv2, pick_folder\n",
    "\n",
    "# --- PART 1: LOADING & PREPARATION ---\n",
    "\n",
    "def load_templates_with_names(folder_path):\n",
    "    \"\"\"\n",
    "    Loads templates and keeps their filenames.\n",
    "    Returns: list of (filename, image_bgr)\n",
    "    \"\"\"\n",
    "    paths = sorted(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
    "    template_data = []\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is not None:\n",
    "            filename = os.path.basename(p)\n",
    "            template_data.append((filename, img))\n",
    "    return template_data\n",
    "\n",
    "\n",
    "def preprocess_templates_for_video(template_data):\n",
    "    \"\"\"\n",
    "    Converts BGR templates to Grayscale ONCE to speed up video processing.\n",
    "    Returns: list of (name, gray_image, width, height)\n",
    "    \"\"\"\n",
    "    processed = []\n",
    "    for name, img_bgr in template_data:\n",
    "        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        h, w = gray.shape\n",
    "        processed.append((name, gray, w, h))\n",
    "    return processed\n",
    "\n",
    "# --- PART 2: MATCHING LOGIC ---\n",
    "\n",
    "def find_best_match_fast(target_gray, gray_templates):\n",
    "    \"\"\"\n",
    "    Optimized matcher for video. \n",
    "    Accepts PRE-CONVERTED gray templates to save time.\n",
    "    \"\"\"\n",
    "    best_match = {\n",
    "        \"score\": -1.0,\n",
    "        \"location\": None,\n",
    "        \"width\": 0,\n",
    "        \"height\": 0,\n",
    "        \"name\": \"\"\n",
    "    }\n",
    "\n",
    "    for name, tmpl_gray, w, h in gray_templates:\n",
    "        res = cv2.matchTemplate(target_gray, tmpl_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, max_val, _, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "        if max_val > best_match[\"score\"]:\n",
    "            best_match[\"score\"] = max_val\n",
    "            best_match[\"location\"] = max_loc\n",
    "            best_match[\"width\"] = w\n",
    "            best_match[\"height\"] = h\n",
    "            best_match[\"name\"] = name\n",
    "\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228dbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PART 3: SHAPE FITTING & VIDEO PROCESSING ---\n",
    "\n",
    "def fit_circle_least_squares(points_xy: np.ndarray):\n",
    "    \"\"\"Least-squares circle fit. Returns (cx, cy, r).\"\"\"\n",
    "    x = points_xy[:, 0]\n",
    "    y = points_xy[:, 1]\n",
    "    A = np.c_[2*x, 2*y, np.ones_like(x)]\n",
    "    b = x**2 + y**2\n",
    "    sol, *_ = np.linalg.lstsq(A, b, rcond=None)\n",
    "    cx, cy, c = sol\n",
    "    r = math.sqrt(max(0.0, c + cx**2 + cy**2))\n",
    "    return float(cx), float(cy), float(r)\n",
    "\n",
    "\n",
    "def fit_ellipse(points_xy):\n",
    "    \"\"\"\n",
    "    Fit an ellipse to (x,y) points using OpenCV.\n",
    "    Needs >= 5 points.\n",
    "    Returns: (center(x,y), axes(rx, ry), angle_deg)\n",
    "    \"\"\"\n",
    "    pts = np.array(points_xy, dtype=np.float32).reshape(-1, 1, 2)\n",
    "    (cx, cy), (MA, ma), angle = cv2.fitEllipse(pts)\n",
    "    rx, ry = MA / 2.0, ma / 2.0\n",
    "    return (float(cx), float(cy)), (float(rx), float(ry)), float(angle)\n",
    "\n",
    "\n",
    "def distributed_frame_indices(total_frames: int, n: int):\n",
    "    \"\"\"\n",
    "    Returns n indices spread across [0, total_frames-1].\n",
    "    Ensures uniqueness and sorted order.\n",
    "    \"\"\"\n",
    "    n = int(max(1, n))\n",
    "    if total_frames <= 0:\n",
    "        return [0]\n",
    "    idx = np.linspace(0, max(0, total_frames-1), n, dtype=int)\n",
    "    idx = np.unique(idx)\n",
    "    return idx.tolist()\n",
    "\n",
    "\n",
    "def process_video_sampled_frames(\n",
    "    video_path: str,\n",
    "    template_folder: str,\n",
    "    n_samples: int = 30,\n",
    "    min_score: float = 0.60,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simplified pipeline:\n",
    "      1) Sample N distributed frames from the video\n",
    "      2) Template-match on ONLY those frames\n",
    "      3) Collect accepted center points\n",
    "      4) Fit ellipse (>=5 points) else circle fallback\n",
    "      5) Overlay the fitted shape on the FIRST frame\n",
    "\n",
    "    Params:\n",
    "      - n_samples: how many distributed frames to evaluate (higher = better fit, slower)\n",
    "      - min_score: NCC threshold\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Could not open video: {video_path}\")\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Grab the first frame for overlay output\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    ok, first_frame = cap.read()\n",
    "    if not ok:\n",
    "        cap.release()\n",
    "        raise RuntimeError(\"Could not read first frame.\")\n",
    "\n",
    "    # Load templates\n",
    "    templates_with_names = load_templates_with_names(template_folder)\n",
    "    gray_templates = preprocess_templates_for_video(templates_with_names)\n",
    "\n",
    "    sample_idxs = distributed_frame_indices(total_frames, n_samples)\n",
    "    print(f\"Total frames: {total_frames} | sampling {len(sample_idxs)} frames\")\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for idx in sample_idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        match = find_best_match_fast(gray, gray_templates)\n",
    "\n",
    "        if match.get(\"location\") is None:\n",
    "            continue\n",
    "\n",
    "        score = float(match[\"score\"])\n",
    "        if score < min_score:\n",
    "            continue\n",
    "\n",
    "        # center coordinate\n",
    "        tlx, tly = match[\"location\"]\n",
    "        w, h = match[\"width\"], match[\"height\"]\n",
    "        cx = tlx + w / 2.0\n",
    "        cy = tly + h / 2.0\n",
    "\n",
    "        rows.append({\n",
    "            \"frame_idx\": int(idx),\n",
    "            \"center_x\": float(cx),\n",
    "            \"center_y\": float(cy),\n",
    "            \"score\": score,\n",
    "            \"template\": match.get(\"name\", \"\")\n",
    "        })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"Accepted points: {len(rows)}\")\n",
    "    if not rows:\n",
    "        print(\"No points accepted. Try lowering min_score or increasing n_samples.\")\n",
    "        return\n",
    "    \n",
    "    # Save CSV\n",
    "    with open(\"zero_points.csv\", \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"frame_idx\", \"center_x\", \"center_y\", \"score\", \"template\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "    print(f\"Saved CSV: zero_points.csv\")\n",
    "    points_xy = [(r[\"center_x\"], r[\"center_y\"]) for r in rows]\n",
    "\n",
    "    # Fit ellipse if possible, else circle fallback\n",
    "    overlay = first_frame.copy()\n",
    "\n",
    "    if len(points_xy) >= 5:\n",
    "        (cx, cy), (rx, ry), angle = fit_ellipse(points_xy)\n",
    "        cv2.ellipse(\n",
    "            overlay,\n",
    "            (int(cx), int(cy)),\n",
    "            (int(rx), int(ry)),\n",
    "            angle,\n",
    "            0, 360,\n",
    "            (0, 0, 255),\n",
    "            3\n",
    "        )\n",
    "        cv2.circle(overlay, (int(cx), int(cy)), 4, (0, 255, 0), -1)\n",
    "        print(f\"Ellipse -> center=({cx:.1f},{cy:.1f}), axes=({rx:.1f},{ry:.1f}), angle={angle:.1f}Â°\")\n",
    "    else:\n",
    "        pts = np.array(points_xy, dtype=np.float64)\n",
    "        cx, cy, r = fit_circle_least_squares(pts)\n",
    "        cv2.circle(overlay, (int(cx), int(cy)), int(r), (0, 0, 255), 3)\n",
    "        cv2.circle(overlay, (int(cx), int(cy)), 4, (0, 255, 0), -1)\n",
    "        print(f\"Circle fallback -> center=({cx:.1f},{cy:.1f}), radius={r:.1f}px (need >=5 points for ellipse)\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Fitted Ellipse Overlay on First Frame\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a343cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ellipse_from_csv(\n",
    "    video_path,\n",
    "    csv_path,\n",
    "    outer_inward_pct,  # less inward (outer halo edge)\n",
    "    inner_inward_pct   # more inward (inner halo edge)\n",
    "):\n",
    "    rows = []\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for r in reader:\n",
    "            rows.append({\n",
    "                \"center_x\": float(r[\"center_x\"]),\n",
    "                \"center_y\": float(r[\"center_y\"]),\n",
    "            })\n",
    "\n",
    "    if len(rows) < 5:\n",
    "        raise ValueError(\"Need at least 5 points to fit an ellipse.\")\n",
    "\n",
    "    if inner_inward_pct <= outer_inward_pct:\n",
    "        raise ValueError(\"inner_inward_pct must be greater than outer_inward_pct\")\n",
    "\n",
    "    # Fit base ellipse (numbers ring)\n",
    "    pts = np.array(\n",
    "        [(r[\"center_x\"], r[\"center_y\"]) for r in rows],\n",
    "        dtype=np.float32\n",
    "    ).reshape(-1, 1, 2)\n",
    "\n",
    "    (cx, cy), (MA, ma), angle = cv2.fitEllipse(pts)\n",
    "    rx, ry = MA / 2.0, ma / 2.0\n",
    "\n",
    "    # Halo boundaries (both inward)\n",
    "    outer_rx = rx * (1.0 - outer_inward_pct)\n",
    "    outer_ry = ry * (1.0 - outer_inward_pct)\n",
    "\n",
    "    inner_rx = rx * (1.0 - inner_inward_pct)\n",
    "    inner_ry = ry * (1.0 - inner_inward_pct)\n",
    "\n",
    "    # Grab random frame\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Could not open video.\")\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    random_idx = random.randint(0, total_frames - 1)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, random_idx)\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"Could not read random frame.\")\n",
    "\n",
    "    overlay = frame.copy()\n",
    "\n",
    "    # Create halo mask (annulus)\n",
    "    mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # Outer boundary (filled)\n",
    "    cv2.ellipse(\n",
    "        mask,\n",
    "        (int(cx), int(cy)),\n",
    "        (int(outer_rx), int(outer_ry)),\n",
    "        angle,\n",
    "        0, 360,\n",
    "        255,\n",
    "        thickness=-1\n",
    "    )\n",
    "\n",
    "    # Inner boundary (cut-out)\n",
    "    cv2.ellipse(\n",
    "        mask,\n",
    "        (int(cx), int(cy)),\n",
    "        (int(inner_rx), int(inner_ry)),\n",
    "        angle,\n",
    "        0, 360,\n",
    "        0,\n",
    "        thickness=-1\n",
    "    )\n",
    "\n",
    "    # Apply semi-transparent halo\n",
    "    halo_color = np.zeros_like(overlay)\n",
    "    halo_color[:] = (255, 0, 0)\n",
    "\n",
    "    alpha = 0.25\n",
    "\n",
    "    overlay = np.where(\n",
    "        mask[:, :, None] == 255,\n",
    "        (overlay * (1 - alpha) + halo_color * alpha).astype(np.uint8),\n",
    "        overlay\n",
    "    )\n",
    "\n",
    "    # Draw ellipse outlines\n",
    "    # Base ellipse (numbers ring)\n",
    "    cv2.ellipse(\n",
    "        overlay,\n",
    "        (int(cx), int(cy)),\n",
    "        (int(rx), int(ry)),\n",
    "        angle,\n",
    "        0, 360,\n",
    "        (0, 0, 255),\n",
    "        2\n",
    "    )\n",
    "\n",
    "    # Outer halo boundary\n",
    "    cv2.ellipse(\n",
    "        overlay,\n",
    "        (int(cx), int(cy)),\n",
    "        (int(outer_rx), int(outer_ry)),\n",
    "        angle,\n",
    "        0, 360,\n",
    "        (0, 165, 255),\n",
    "        2\n",
    "    )\n",
    "\n",
    "    # Inner halo boundary\n",
    "    cv2.ellipse(\n",
    "        overlay,\n",
    "        (int(cx), int(cy)),\n",
    "        (int(inner_rx), int(inner_ry)),\n",
    "        angle,\n",
    "        0, 360,\n",
    "        (0, 255, 0),\n",
    "        2\n",
    "    )\n",
    "\n",
    "    # Display with legend\n",
    "    overlay_rgb = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(overlay_rgb)\n",
    "\n",
    "    base_legend  = mlines.Line2D([], [], color='red',    linewidth=2, label='Numbers ring')\n",
    "    outer_legend = mlines.Line2D([], [], color='orange', linewidth=2, label='Outer halo boundary')\n",
    "    inner_legend = mlines.Line2D([], [], color='green',  linewidth=2, label='Inner halo boundary')\n",
    "    fill_legend  = mlines.Line2D([], [], color='blue',   linewidth=6, alpha=0.5, label='Halo band')\n",
    "\n",
    "    plt.legend(\n",
    "        handles=[base_legend, outer_legend, inner_legend, fill_legend],\n",
    "        loc='upper right',\n",
    "        framealpha=0.9\n",
    "    )\n",
    "\n",
    "    plt.title(\n",
    "        f\"Halo Band (Inward Offsets)\\n\"\n",
    "        f\"Outer: {outer_inward_pct*100:.1f}% | \"\n",
    "        f\"Inner: {inner_inward_pct*100:.1f}% | \"\n",
    "        f\"Frame {random_idx}\"\n",
    "    )\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2968e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "# Settings\n",
    "_, input_video_path = pick_video_cv2(title=\"Select Input Video\")\n",
    "templates_dir = pick_folder(title=\"Select Template Folder\")\n",
    "\n",
    "N_SAMPLES = 10      # How many distributed frames to evaluate\n",
    "MIN_SCORE = 0.80    # Lower if too few points are accepted\n",
    "\n",
    "process_video_sampled_frames(\n",
    "    video_path=input_video_path,\n",
    "    template_folder=templates_dir,\n",
    "    n_samples=N_SAMPLES,\n",
    "    min_score=MIN_SCORE\n",
    ")\n",
    "\n",
    "draw_ellipse_from_csv(\n",
    "    video_path=input_video_path,\n",
    "    csv_path=\"zero_points.csv\",\n",
    "    outer_inward_pct=0.10,   \n",
    "    inner_inward_pct=0.30\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
