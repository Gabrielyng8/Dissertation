{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8b7cc8",
   "metadata": {},
   "source": [
    "# Roulette ‘0’ Pocket Calibration & Overlay (Template Matching)\n",
    "\n",
    "1) **Calibration (setup video)**: track the **‘0’ pocket** with template matching, save points, fit a **circle/ellipse**, save calibration.\n",
    "\n",
    "2) **Overlay (new image/video)**: load the calibration and overlay the fitted curve onto new frames.\n",
    "\n",
    "> Assumes a similar camera setup (same framing / minimal movement)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672afbd",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "Install requirements (if needed):\n",
    "\n",
    "```bash\n",
    "pip install opencv-python numpy\n",
    "```\n",
    "\n",
    "Put your templates (cropped images of the `0` pocket) in a folder, e.g. `templates_zero/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af6645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "\n",
    "# -------------------------\n",
    "# USER PATHS (EDIT THESE)\n",
    "# -------------------------\n",
    "\n",
    "# Output files\n",
    "OUT_DIR = Path(\"roulette_calibration_out\")\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "TRACK_CSV_PATH    = OUT_DIR / \"zero_track_points.csv\"\n",
    "CALIB_JSON_PATH   = OUT_DIR / \"zero_path_calibration.json\"\n",
    "OVERLAY_VIDEO_OUT = OUT_DIR / \"overlay_output.mp4\"\n",
    "\n",
    "# -------------------------\n",
    "# TRACKING PARAMS (TUNE)\n",
    "# -------------------------\n",
    "MIN_SCORE    = 0.60   # NCC threshold (0..1). Raise if you get false matches.\n",
    "MAX_JUMP     = 50     # Max pixel jump between consecutive accepted detections.\n",
    "SMOOTH_K     = 3      # Deque length for light smoothing (median).\n",
    "FRAME_STEP   = 1      # Process every Nth frame (1=all frames).\n",
    "SEARCH_ROI   = None   # Optional: (x, y, w, h) to restrict search, else None.\n",
    "DEBUG_PREVIEW = False # True to show a live debug window (may not work in all notebook setups).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2616356",
   "metadata": {},
   "source": [
    "## 1) Helper Functions\n",
    "\n",
    "- `cv2.matchTemplate` with `TM_CCOEFF_NORMED` (normalized cross-correlation)\n",
    "- best match across all templates\n",
    "- jump filter + median smoothing\n",
    "- ellipse fit via `cv2.fitEllipse` (needs ≥ 5 points), else circle fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc68de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_templates(folder_path: str):\n",
    "    folder = Path(folder_path)\n",
    "    if not folder.exists():\n",
    "        raise FileNotFoundError(f\"Templates folder not found: {folder.resolve()}\")\n",
    "\n",
    "    exts = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".webp\")\n",
    "    template_paths = [p for p in sorted(folder.iterdir()) if p.suffix.lower() in exts]\n",
    "    if not template_paths:\n",
    "        raise ValueError(f\"No template images found in: {folder.resolve()}\")\n",
    "\n",
    "    templates = []\n",
    "    for p in template_paths:\n",
    "        img = cv2.imread(str(p), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        templates.append((p.name, img))\n",
    "\n",
    "    if not templates:\n",
    "        raise ValueError(\"Templates could not be loaded (all read as None).\")\n",
    "    return templates\n",
    "\n",
    "\n",
    "def best_template_match(frame_gray: np.ndarray, templates):\n",
    "    best = None\n",
    "    for name, tmpl in templates:\n",
    "        if frame_gray.shape[0] < tmpl.shape[0] or frame_gray.shape[1] < tmpl.shape[1]:\n",
    "            continue\n",
    "\n",
    "        res = cv2.matchTemplate(frame_gray, tmpl, cv2.TM_CCOEFF_NORMED)\n",
    "        _, max_val, _, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "        if best is None or max_val > best[\"score\"]:\n",
    "            best = {\n",
    "                \"name\": name,\n",
    "                \"score\": float(max_val),\n",
    "                \"top_left\": (int(max_loc[0]), int(max_loc[1])),\n",
    "                \"w\": int(tmpl.shape[1]),\n",
    "                \"h\": int(tmpl.shape[0]),\n",
    "            }\n",
    "    return best\n",
    "\n",
    "\n",
    "def _dist(p1, p2):\n",
    "    return math.hypot(p1[0]-p2[0], p1[1]-p2[1])\n",
    "\n",
    "\n",
    "def track_zero_points(\n",
    "    video_path: str,\n",
    "    templates_dir: str,\n",
    "    min_score: float = 0.60,\n",
    "    max_jump: float = 80,\n",
    "    smooth_k: int = 5,\n",
    "    frame_step: int = 1,\n",
    "    search_roi=None,\n",
    "    debug_preview: bool = False\n",
    "):\n",
    "    templates = load_templates(templates_dir)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Could not open video: {video_path}\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    points = []\n",
    "    recent = deque(maxlen=max(1, smooth_k))\n",
    "    prev = None\n",
    "\n",
    "    frame_idx = -1\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        frame_idx += 1\n",
    "\n",
    "        if frame_step > 1 and (frame_idx % frame_step != 0):\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # ROI crop (optional)\n",
    "        roi_offset = (0, 0)\n",
    "        gray_search = gray\n",
    "        if search_roi is not None:\n",
    "            x, y, w, h = search_roi\n",
    "            x, y = max(0, x), max(0, y)\n",
    "            w = min(w, width - x)\n",
    "            h = min(h, height - y)\n",
    "            gray_search = gray[y:y+h, x:x+w]\n",
    "            roi_offset = (x, y)\n",
    "\n",
    "        best = best_template_match(gray_search, templates)\n",
    "        if best is None:\n",
    "            continue\n",
    "\n",
    "        score = best[\"score\"]\n",
    "        if score < min_score:\n",
    "            continue\n",
    "\n",
    "        tl = best[\"top_left\"]\n",
    "        cx = tl[0] + best[\"w\"] / 2.0 + roi_offset[0]\n",
    "        cy = tl[1] + best[\"h\"] / 2.0 + roi_offset[1]\n",
    "        curr = (float(cx), float(cy))\n",
    "\n",
    "        # Jump filter\n",
    "        if prev is not None and _dist(prev, curr) > max_jump:\n",
    "            continue\n",
    "\n",
    "        recent.append(curr)\n",
    "        smoothed = (float(np.median([p[0] for p in recent])),\n",
    "                    float(np.median([p[1] for p in recent])))\n",
    "\n",
    "        prev = smoothed\n",
    "\n",
    "        points.append({\n",
    "            \"frame_idx\": int(frame_idx),\n",
    "            \"x\": smoothed[0],\n",
    "            \"y\": smoothed[1],\n",
    "            \"raw_x\": curr[0],\n",
    "            \"raw_y\": curr[1],\n",
    "            \"score\": float(score),\n",
    "            \"template\": best[\"name\"],\n",
    "        })\n",
    "\n",
    "        if debug_preview:\n",
    "            vis = frame.copy()\n",
    "            if search_roi is not None:\n",
    "                x, y, w, h = search_roi\n",
    "                cv2.rectangle(vis, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "\n",
    "            raw_tl = (int(tl[0] + roi_offset[0]), int(tl[1] + roi_offset[1]))\n",
    "            raw_br = (raw_tl[0] + best[\"w\"], raw_tl[1] + best[\"h\"])\n",
    "            cv2.rectangle(vis, raw_tl, raw_br, (0, 255, 0), 2)\n",
    "            cv2.circle(vis, (int(smoothed[0]), int(smoothed[1])), 4, (0, 0, 255), -1)\n",
    "\n",
    "            cv2.putText(vis, f\"score={score:.3f} tmpl={best['name']}\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"debug tracking\", vis)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    if debug_preview:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    meta = {\n",
    "        \"fps\": float(fps),\n",
    "        \"width\": int(width),\n",
    "        \"height\": int(height),\n",
    "        \"frame_count\": int(frame_count),\n",
    "        \"frame_step\": int(frame_step),\n",
    "    }\n",
    "    return points, meta\n",
    "\n",
    "\n",
    "def fit_circle_least_squares(points_xy: np.ndarray):\n",
    "    x = points_xy[:, 0]\n",
    "    y = points_xy[:, 1]\n",
    "    A = np.c_[2*x, 2*y, np.ones_like(x)]\n",
    "    b = x**2 + y**2\n",
    "    sol, *_ = np.linalg.lstsq(A, b, rcond=None)\n",
    "    cx, cy, c = sol\n",
    "    r = math.sqrt(max(0.0, c + cx**2 + cy**2))\n",
    "    return float(cx), float(cy), float(r)\n",
    "\n",
    "\n",
    "def fit_ellipse_or_circle(points_xy: np.ndarray):\n",
    "    if len(points_xy) >= 5:\n",
    "        pts = points_xy.astype(np.float32).reshape(-1, 1, 2)\n",
    "        (cx, cy), (MA, ma), angle = cv2.fitEllipse(pts)  # axis lengths\n",
    "        return {\n",
    "            \"type\": \"ellipse\",\n",
    "            \"center\": [float(cx), float(cy)],\n",
    "            \"axes\": [float(MA/2.0), float(ma/2.0)],  # radii\n",
    "            \"angle_deg\": float(angle),\n",
    "        }\n",
    "    cx, cy, r = fit_circle_least_squares(points_xy)\n",
    "    return {\"type\": \"circle\", \"center\": [cx, cy], \"radius\": r}\n",
    "\n",
    "\n",
    "def draw_calibration_overlay(frame_bgr: np.ndarray, geom: dict, thickness: int = 2):\n",
    "    out = frame_bgr.copy()\n",
    "    if geom[\"type\"] == \"ellipse\":\n",
    "        cx, cy = geom[\"center\"]\n",
    "        ax, ay = geom[\"axes\"]\n",
    "        angle = geom[\"angle_deg\"]\n",
    "        cv2.ellipse(out, (int(cx), int(cy)), (int(ax), int(ay)), angle, 0, 360, (0, 0, 255), thickness)\n",
    "    else:\n",
    "        cx, cy = geom[\"center\"]\n",
    "        r = geom[\"radius\"]\n",
    "        cv2.circle(out, (int(cx), int(cy)), int(r), (0, 0, 255), thickness)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b14dd4f",
   "metadata": {},
   "source": [
    "## 2) Calibration Run (Setup Video)\n",
    "\n",
    "This cell tracks the `0` pocket, saves a CSV of points, fits ellipse/circle, and saves a JSON calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65505689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 316 points.\n",
      "Video meta: {'fps': 30.0, 'width': 970, 'height': 726, 'frame_count': 333, 'frame_step': 1}\n"
     ]
    }
   ],
   "source": [
    "from utils.file_dialog_utils import pick_video_cv2, pick_image_cv2, pick_folder\n",
    "\n",
    "_, SETUP_VIDEO_PATH = pick_video_cv2(title=\"Select Input Video\")\n",
    "TEMPLATES_DIR = pick_folder(title=\"Select Template Folder\")\n",
    "\n",
    "points, meta = track_zero_points(\n",
    "    video_path=SETUP_VIDEO_PATH,\n",
    "    templates_dir=TEMPLATES_DIR,\n",
    "    min_score=MIN_SCORE,\n",
    "    max_jump=MAX_JUMP,\n",
    "    smooth_k=SMOOTH_K,\n",
    "    frame_step=FRAME_STEP,\n",
    "    search_roi=SEARCH_ROI,\n",
    "    debug_preview=DEBUG_PREVIEW\n",
    ")\n",
    "\n",
    "print(f\"Collected {len(points)} points.\")\n",
    "print(\"Video meta:\", meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6477e2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\Gabriel\\Documents\\Dissertation\\Code\\notebooks\\roulette_calibration_out\\zero_track_points.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save points to CSV\n",
    "import csv\n",
    "\n",
    "with open(TRACK_CSV_PATH, \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"frame_idx\", \"x\", \"y\", \"raw_x\", \"raw_y\", \"score\", \"template\"])\n",
    "    for p in points:\n",
    "        w.writerow([p[\"frame_idx\"], p[\"x\"], p[\"y\"], p[\"raw_x\"], p[\"raw_y\"], p[\"score\"], p[\"template\"]])\n",
    "\n",
    "print(\"Saved:\", TRACK_CSV_PATH.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a11375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved calibration JSON: C:\\Users\\Gabriel\\Documents\\Dissertation\\Code\\notebooks\\roulette_calibration_out\\zero_path_calibration.json\n",
      "Geometry: {'type': 'ellipse', 'center': [488.2545166015625, 394.57574462890625], 'axes': [256.97064208984375, 275.6770935058594], 'angle_deg': 91.70647430419922}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5712\\913877172.py:7: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"created_utc\": datetime.datetime.utcnow().isoformat() + \"Z\",\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit geometry + save calibration JSON\n",
    "pts_xy = np.array([[p[\"x\"], p[\"y\"]] for p in points], dtype=np.float64)\n",
    "geom = fit_ellipse_or_circle(pts_xy)\n",
    "\n",
    "import datetime\n",
    "calibration = {\n",
    "    \"created_utc\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"source_setup_video\": str(SETUP_VIDEO_PATH),\n",
    "    \"templates_dir\": str(TEMPLATES_DIR),\n",
    "    \"tracking_params\": {\n",
    "        \"min_score\": MIN_SCORE,\n",
    "        \"max_jump\": MAX_JUMP,\n",
    "        \"smooth_k\": SMOOTH_K,\n",
    "        \"frame_step\": FRAME_STEP,\n",
    "        \"search_roi\": SEARCH_ROI,\n",
    "    },\n",
    "    \"video_meta\": meta,\n",
    "    \"geometry\": geom,\n",
    "    \"point_count\": int(len(points)),\n",
    "}\n",
    "\n",
    "with open(CALIB_JSON_PATH, \"w\") as f:\n",
    "    json.dump(calibration, f, indent=2)\n",
    "\n",
    "print(\"Saved calibration JSON:\", CALIB_JSON_PATH.resolve())\n",
    "print(\"Geometry:\", geom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902d497",
   "metadata": {},
   "source": [
    "## 3) Quick sanity check\n",
    "\n",
    "This draws the fitted path on the first frame of the setup video and saves an image preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804cd48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote preview image: C:\\Users\\Gabriel\\Documents\\Dissertation\\Code\\notebooks\\roulette_calibration_out\\calibration_preview.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(SETUP_VIDEO_PATH)\n",
    "ok, frame0 = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if not ok:\n",
    "    raise RuntimeError(\"Could not read first frame for preview.\")\n",
    "\n",
    "preview = draw_calibration_overlay(frame0, geom, thickness=3)\n",
    "preview_path = OUT_DIR / \"calibration_preview.png\"\n",
    "cv2.imwrite(str(preview_path), preview)\n",
    "print(\"Wrote preview image:\", preview_path.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94a931d",
   "metadata": {},
   "source": [
    "## 4) Overlay onto a new image or video\n",
    "\n",
    "Set `NEW_IMAGE_PATH` and/or `NEW_VIDEO_PATH` and run the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7aed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded geometry: {'type': 'ellipse', 'center': [488.2545166015625, 394.57574462890625], 'axes': [256.97064208984375, 275.6770935058594], 'angle_deg': 91.70647430419922}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load calibration (useful if you restart the notebook)\n",
    "with open(CALIB_JSON_PATH, \"r\") as f:\n",
    "    calibration = json.load(f)\n",
    "geom = calibration[\"geometry\"]\n",
    "\n",
    "_ , NEW_IMAGE_PATH = pick_image_cv2(title=\"Select New Overlay Image (or Cancel to skip)\")\n",
    "_ , NEW_VIDEO_PATH = pick_video_cv2(title=\"Select New Overlay Video (or Cancel to skip)\")\n",
    "\n",
    "print(\"Loaded geometry:\", geom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6bb6274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved overlay image: C:\\Users\\Gabriel\\Documents\\Dissertation\\Code\\notebooks\\roulette_calibration_out\\overlay_image.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Image overlay\n",
    "if NEW_IMAGE_PATH and os.path.exists(NEW_IMAGE_PATH):\n",
    "    img = cv2.imread(NEW_IMAGE_PATH)\n",
    "    if img is None:\n",
    "        raise RuntimeError(\"Could not read NEW_IMAGE_PATH\")\n",
    "    out = draw_calibration_overlay(img, geom, thickness=3)\n",
    "    out_path = OUT_DIR / \"overlay_image.png\"\n",
    "    cv2.imwrite(str(out_path), out)\n",
    "    print(\"Saved overlay image:\", out_path.resolve())\n",
    "else:\n",
    "    print(\"Skipping image overlay (set NEW_IMAGE_PATH to an existing file).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab62765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved overlay video: C:\\Users\\Gabriel\\Documents\\Dissertation\\Code\\notebooks\\roulette_calibration_out\\overlay_output.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Video overlay\n",
    "if NEW_VIDEO_PATH and os.path.exists(NEW_VIDEO_PATH):\n",
    "    cap = cv2.VideoCapture(NEW_VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Could not open NEW_VIDEO_PATH\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(str(OVERLAY_VIDEO_OUT), fourcc, fps, (width, height))\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        overlay = draw_calibration_overlay(frame, geom, thickness=2)\n",
    "        writer.write(overlay)\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    print(\"Saved overlay video:\", OVERLAY_VIDEO_OUT.resolve())\n",
    "else:\n",
    "    print(\"Skipping video overlay (set NEW_VIDEO_PATH to an existing file).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ccdc22",
   "metadata": {},
   "source": [
    "## Optional: Make it more robust\n",
    "\n",
    "If your camera framing shifts between videos, you can:\n",
    "- detect stable landmarks (rim / center hub)\n",
    "- estimate a transform (similarity/homography)\n",
    "- warp the calibration geometry before drawing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
