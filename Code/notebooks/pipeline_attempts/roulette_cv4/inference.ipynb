{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca73de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from ultralytics import YOLO\n",
    "\n",
    "p = Path.cwd()\n",
    "while p != p.parent and not (p / \"utils\").exists():\n",
    "    p = p.parent\n",
    "\n",
    "sys.path.insert(0, str(p))\n",
    "\n",
    "from utils.file_dialog_utils import pick_video_cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02636bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- USER CONFIGURATION ---\n",
    "\n",
    "# Inputs\n",
    "_ , VIDEO_SOURCE  = pick_video_cv2(title=\"Select Roulette Video\")\n",
    "\n",
    "GEOMETRY_JSON = \"C:\\\\Users\\\\Gabriel\\\\Documents\\\\Dissertation\\\\Code\\\\notebooks\\\\pipeline_attempts\\\\roulette_cv4\\\\wheel_geometry.json\"   # produced by setup.ipynb\n",
    "YOLO_WEIGHTS  = \"C:\\\\Users\\\\Gabriel\\\\Documents\\\\Dissertation\\\\Code\\\\models\\\\yolo\\\\RD2_Model.pt\"                     # trained YOLO weights (Ultralytics)\n",
    "\n",
    "# Detection settings\n",
    "BALL_CLASS_ID = 0       # YOLO class index for the ball\n",
    "CONF_THRES    = 0.40\n",
    "IOU_THRES     = 0.70\n",
    "\n",
    "# Landing logic\n",
    "LANDING_SECONDS = 1.5   # how long (continuous) ball must remain in halo\n",
    "RESET_ON_LOST   = True  # if detection is lost, reset timer\n",
    "REARM_SECONDS   = 1.0   # must be out-of-halo (or missing) this long before next landing can be detected\n",
    "\n",
    "# Screenshot burst after landing\n",
    "LANDING_SHOT_COUNT        = 5    # total screenshots per landing (including first frame)\n",
    "LANDING_SHOT_DURATION_SEC = 1.5  # spread screenshots across this duration\n",
    "\n",
    "# Outputs\n",
    "OUTPUT_DIR           = \"inference_output\"\n",
    "SAVE_ANNOTATED_VIDEO = True\n",
    "ANNOTATED_VIDEO_PATH = os.path.join(OUTPUT_DIR, \"annotated.mp4\")\n",
    "RESULTS_JSONL_PATH   = os.path.join(OUTPUT_DIR, \"results_events.jsonl\")\n",
    "\n",
    "# Display (set False for headless runs)\n",
    "SHOW_WINDOW  = True\n",
    "WINDOW_NAME  = \"Halo + YOLO Inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OUTPUT DIRECTORY SETUP ---\n",
    "\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "print(\"OUTPUT_DIR:\", Path(OUTPUT_DIR).resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d6ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HELPER CLASSES AND FUNCTIONS ---\n",
    "\n",
    "@dataclass\n",
    "class HaloParams:\n",
    "    cx: float\n",
    "    cy: float\n",
    "    outer_rx: float\n",
    "    outer_ry: float\n",
    "    inner_rx: float\n",
    "    inner_ry: float\n",
    "    angle_deg: float\n",
    "\n",
    "def load_halo_from_geometry_json(path: str) -> HaloParams:\n",
    "    with open(path, \"r\") as f:\n",
    "        geom = json.load(f)\n",
    "\n",
    "    cx = float(geom[\"ellipse\"][\"cx\"])\n",
    "    cy = float(geom[\"ellipse\"][\"cy\"])\n",
    "    rx = float(geom[\"ellipse\"][\"rx\"])\n",
    "    ry = float(geom[\"ellipse\"][\"ry\"])\n",
    "    angle_deg = float(geom[\"ellipse\"][\"rotation_deg\"])\n",
    "\n",
    "    outer_inward = float(geom[\"halo\"][\"outer_inward_pct\"])\n",
    "    inner_inward = float(geom[\"halo\"][\"inner_inward_pct\"])\n",
    "\n",
    "    outer_rx = rx * (1.0 - outer_inward)\n",
    "    outer_ry = ry * (1.0 - outer_inward)\n",
    "\n",
    "    inner_rx = rx * (1.0 - inner_inward)\n",
    "    inner_ry = ry * (1.0 - inner_inward)\n",
    "\n",
    "    return HaloParams(\n",
    "        cx=cx, cy=cy,\n",
    "        outer_rx=outer_rx, outer_ry=outer_ry,\n",
    "        inner_rx=inner_rx, inner_ry=inner_ry,\n",
    "        angle_deg=angle_deg\n",
    "    )\n",
    "\n",
    "def point_in_rotated_ellipse(px: float, py: float, cx: float, cy: float, rx: float, ry: float, angle_deg: float) -> bool:\n",
    "    \"\"\"Return True if point (px,py) lies inside the rotated ellipse.\"\"\"\n",
    "    if rx <= 0 or ry <= 0:\n",
    "        return False\n",
    "\n",
    "    ang = math.radians(angle_deg)\n",
    "    cos_a = math.cos(ang)\n",
    "    sin_a = math.sin(ang)\n",
    "\n",
    "    dx = px - cx\n",
    "    dy = py - cy\n",
    "\n",
    "    # rotate by -angle to align ellipse to axes\n",
    "    x =  cos_a * dx + sin_a * dy\n",
    "    y = -sin_a * dx + cos_a * dy\n",
    "\n",
    "    val = (x * x) / (rx * rx) + (y * y) / (ry * ry)\n",
    "    return val <= 1.0\n",
    "\n",
    "def point_in_halo(px: float, py: float, halo: HaloParams) -> bool:\n",
    "    inside_outer = point_in_rotated_ellipse(px, py, halo.cx, halo.cy, halo.outer_rx, halo.outer_ry, halo.angle_deg)\n",
    "    inside_inner = point_in_rotated_ellipse(px, py, halo.cx, halo.cy, halo.inner_rx, halo.inner_ry, halo.angle_deg)\n",
    "    return inside_outer and (not inside_inner)\n",
    "\n",
    "def draw_halo(frame_bgr: np.ndarray, halo: HaloParams) -> np.ndarray:\n",
    "    \"\"\"Draw the halo boundaries on the frame (in-place) and return it.\"\"\"\n",
    "    cv2.ellipse(frame_bgr, (int(halo.cx), int(halo.cy)), (int(halo.outer_rx), int(halo.outer_ry)), halo.angle_deg, 0, 360, (255, 255, 0), 2)\n",
    "    cv2.ellipse(frame_bgr, (int(halo.cx), int(halo.cy)), (int(halo.inner_rx), int(halo.inner_ry)), halo.angle_deg, 0, 360, (0, 255, 255), 2)\n",
    "    return frame_bgr\n",
    "\n",
    "halo = load_halo_from_geometry_json(GEOMETRY_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SCREENSHOT UTILITY ---\n",
    "\n",
    "def save_landing_screenshot(\n",
    "    frame_bgr,\n",
    "    spin_id=None,\n",
    "    frame_idx=None,\n",
    "    time_s=None,\n",
    "    shot_idx=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Saves a clean screenshot of a landing frame.\n",
    "\n",
    "    Parameters:\n",
    "        frame_bgr  : raw OpenCV BGR frame (before drawing overlays)\n",
    "        spin_id    : optional spin identifier\n",
    "        frame_idx  : frame index at landing\n",
    "        time_s     : timestamp in seconds\n",
    "        shot_idx   : optional screenshot index within the landing burst\n",
    "\n",
    "    Returns:\n",
    "        filename : name of the saved screenshot file\n",
    "    \"\"\"\n",
    "\n",
    "    # Build filename\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\", time.gmtime())\n",
    "\n",
    "    spin_part = f\"spin_{spin_id}_\" if spin_id is not None else \"\"\n",
    "    shot_part = f\"shot_{shot_idx}_\" if shot_idx is not None else \"\"\n",
    "    frame_part = f\"f{frame_idx}_\" if frame_idx is not None else \"\"\n",
    "    time_part = f\"{time_s:.3f}s_\" if time_s is not None else \"\"\n",
    "\n",
    "    filename = f\"{spin_part}{shot_part}{frame_part}{time_part}{timestamp}.png\"\n",
    "\n",
    "    screenshots_dir = os.path.join(OUTPUT_DIR, \"screenshots\")\n",
    "    os.makedirs(screenshots_dir, exist_ok=True)\n",
    "    save_path = os.path.join(screenshots_dir, filename)\n",
    "\n",
    "    # Save raw frame (NO overlays)\n",
    "    cv2.imwrite(save_path, frame_bgr)\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN INFERENCE LOOP ---\n",
    "\n",
    "# Load model\n",
    "model = YOLO(YOLO_WEIGHTS)\n",
    "\n",
    "# Open source: file path OR camera index OR RTSP url\n",
    "cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Failed to open VIDEO_SOURCE: {VIDEO_SOURCE}\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if not fps or fps <= 1e-3:\n",
    "    fps = 30.0\n",
    "frame_dt = 1.0 / fps\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "writer = None\n",
    "if SAVE_ANNOTATED_VIDEO:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(ANNOTATED_VIDEO_PATH, fourcc, fps, (w, h))\n",
    "\n",
    "if SHOW_WINDOW:\n",
    "    cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(WINDOW_NAME, 1280, 720)\n",
    "\n",
    "# Landing state\n",
    "time_in_halo = 0.0\n",
    "time_outside = 0.0\n",
    "armed = True          # can we trigger landing?\n",
    "landed = False\n",
    "\n",
    "spin_counter = 0\n",
    "pending_screenshots = []\n",
    "\n",
    "# For saving events\n",
    "def append_event(event: dict, path: str = RESULTS_JSONL_PATH):\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(event) + \"\\n\")\n",
    "\n",
    "frame_idx = -1\n",
    "last_ball = None  # store best ball detection for debug\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        frame_clean = frame.copy()  # for saving screenshots without overlays\n",
    "\n",
    "        frame_idx += 1\n",
    "        t_s = frame_idx / fps\n",
    "\n",
    "        # Run YOLO\n",
    "        results = model.predict(\n",
    "            source=frame,\n",
    "            conf=CONF_THRES,\n",
    "            iou=IOU_THRES,\n",
    "            device=0,\n",
    "            verbose=False\n",
    "        )\n",
    "        r = results[0]\n",
    "        display = r.plot()  # draws boxes/labels\n",
    "\n",
    "        # pick best ball detection (highest conf)\n",
    "        best = None\n",
    "        if r.boxes is not None and len(r.boxes) > 0:\n",
    "            for box in r.boxes:\n",
    "                cls_id = int(box.cls[0].item())\n",
    "                if cls_id != BALL_CLASS_ID:\n",
    "                    continue\n",
    "                conf = float(box.conf[0].item())\n",
    "                if best is None or conf > best[\"conf\"]:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                    best = {\"conf\": conf, \"xyxy\": [x1, y1, x2, y2]}\n",
    "\n",
    "        in_halo = False\n",
    "        if best is not None:\n",
    "            x1, y1, x2, y2 = best[\"xyxy\"]\n",
    "            bx = (x1 + x2) / 2.0\n",
    "            by = (y1 + y2) / 2.0\n",
    "            in_halo = point_in_halo(bx, by, halo)\n",
    "\n",
    "            # Draw ball center\n",
    "            cv2.circle(display, (int(bx), int(by)), 4, (0, 0, 255), -1)\n",
    "            last_ball = {\"conf\": best[\"conf\"], \"center\": [bx, by]}\n",
    "        else:\n",
    "            in_halo = False   # treat missing as outside for re-arming\n",
    "\n",
    "        if armed:\n",
    "            if in_halo:\n",
    "                time_in_halo += frame_dt\n",
    "                time_outside = 0.0\n",
    "            else:\n",
    "                time_in_halo = 0.0\n",
    "                time_outside += frame_dt\n",
    "\n",
    "            if time_in_halo >= LANDING_SECONDS:\n",
    "                landed = True\n",
    "                armed = False\n",
    "                time_outside = 0.0\n",
    "\n",
    "                landing_frame_idx = frame_idx\n",
    "                landing_time_s = t_s\n",
    "\n",
    "                spin_counter += 1\n",
    "\n",
    "                shot_count = max(1, int(LANDING_SHOT_COUNT))\n",
    "                duration_frames = max(0, int(round(LANDING_SHOT_DURATION_SEC * fps)))\n",
    "                if shot_count == 1 or duration_frames == 0:\n",
    "                    shot_offsets = [0]\n",
    "                else:\n",
    "                    shot_offsets = np.round(\n",
    "                        np.linspace(0, duration_frames, num=shot_count)\n",
    "                    ).astype(int).tolist()\n",
    "\n",
    "                for shot_idx, offset in enumerate(shot_offsets, start=1):\n",
    "                    pending_screenshots.append({\n",
    "                        \"spin_id\": spin_counter,\n",
    "                        \"shot_idx\": shot_idx,\n",
    "                        \"target_frame_idx\": landing_frame_idx + int(offset),\n",
    "                    })\n",
    "\n",
    "                event = {\n",
    "                    \"event\": \"landing\",\n",
    "                    \"spin_id\": spin_counter,\n",
    "                    \"frame_idx\": landing_frame_idx,\n",
    "                    \"time_s\": landing_time_s,\n",
    "                    \"ball\": last_ball,\n",
    "                    \"fps\": fps,\n",
    "                    \"screenshot_count\": shot_count,\n",
    "                    \"screenshot_duration_sec\": LANDING_SHOT_DURATION_SEC,\n",
    "                    \"geometry_json\": GEOMETRY_JSON,\n",
    "                    \"video_source\": VIDEO_SOURCE,\n",
    "                    \"timestamp_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "                }\n",
    "                append_event(event)\n",
    "                print(f\"[LANDED] frame={landing_frame_idx} t={landing_time_s:.3f}s (saved to {RESULTS_JSONL_PATH})\")\n",
    "        else:\n",
    "            # not armed: wait until ball is outside (or missing) for long enough\n",
    "            if not in_halo:\n",
    "                time_outside += frame_dt\n",
    "                if time_outside >= REARM_SECONDS:\n",
    "                    armed = True\n",
    "                    landed = False\n",
    "                    time_in_halo = 0.0\n",
    "                    time_outside = 0.0\n",
    "            else:\n",
    "                time_outside = 0.0\n",
    "\n",
    "        if pending_screenshots:\n",
    "            remaining = []\n",
    "            for shot in pending_screenshots:\n",
    "                if frame_idx >= shot[\"target_frame_idx\"]:\n",
    "                    screenshot_name = save_landing_screenshot(\n",
    "                        frame_clean,\n",
    "                        spin_id=shot[\"spin_id\"],\n",
    "                        frame_idx=frame_idx,\n",
    "                        time_s=t_s,\n",
    "                        shot_idx=shot[\"shot_idx\"]\n",
    "                    )\n",
    "\n",
    "                    shot_event = {\n",
    "                        \"event\": \"screenshot\",\n",
    "                        \"spin_id\": shot[\"spin_id\"],\n",
    "                        \"shot_idx\": shot[\"shot_idx\"],\n",
    "                        \"frame_idx\": frame_idx,\n",
    "                        \"time_s\": t_s,\n",
    "                        \"ball\": last_ball,\n",
    "                        \"screenshot\": screenshot_name,\n",
    "                        \"fps\": fps,\n",
    "                        \"geometry_json\": GEOMETRY_JSON,\n",
    "                        \"video_source\": VIDEO_SOURCE,\n",
    "                        \"timestamp_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "                    }\n",
    "                    append_event(shot_event)\n",
    "                else:\n",
    "                    remaining.append(shot)\n",
    "            pending_screenshots = remaining\n",
    "\n",
    "        # Draw halo boundaries + status\n",
    "        draw_halo(display, halo)\n",
    "        status = f\"in_halo_time={time_in_halo:.2f}s / {LANDING_SECONDS:.2f}s | landed={landed}\"\n",
    "        cv2.putText(display, status, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "\n",
    "        if landed:\n",
    "            cv2.putText(display, \"BALL HAS LANDED\", (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "        # Output\n",
    "        if writer is not None:\n",
    "            writer.write(display)\n",
    "\n",
    "        if SHOW_WINDOW:\n",
    "            cv2.imshow(WINDOW_NAME, display)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key in (ord(\"q\"), 27):  # q or ESC\n",
    "                break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "    if SHOW_WINDOW:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\nAnnotated video:\", ANNOTATED_VIDEO_PATH if SAVE_ANNOTATED_VIDEO else \"(disabled)\")\n",
    "print(\"Events:\", RESULTS_JSONL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc10048",
   "metadata": {},
   "source": [
    "## Live stream later (camera / RTSP)\n",
    "\n",
    "When youâ€™re ready to swap `VIDEO_SOURCE` from a file to a live stream:\n",
    "\n",
    "- USB webcam: `VIDEO_SOURCE = 0`\n",
    "- RTSP: `VIDEO_SOURCE = \"rtsp://user:pass@host:554/stream1\"`\n",
    "\n",
    "The loop already uses `cv2.VideoCapture(VIDEO_SOURCE)` so the only change should be the source string/index.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
