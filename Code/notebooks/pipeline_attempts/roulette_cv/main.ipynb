{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils.file_dialog_utils import pick_video_cv2, pick_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e91d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOADING & PREPARATION ---\n",
    "def load_templates_with_names(folder_path):\n",
    "    \"\"\"\n",
    "    Loads templates and keeps their filenames.\n",
    "    Returns: list of (filename, image_bgr)\n",
    "    \"\"\"\n",
    "    paths = sorted(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
    "    template_data = []\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is not None:\n",
    "            filename = os.path.basename(p)\n",
    "            template_data.append((filename, img))\n",
    "    return template_data\n",
    "\n",
    "\n",
    "def preprocess_templates_for_video(template_data):\n",
    "    \"\"\"\n",
    "    Converts BGR templates to Grayscale ONCE to speed up video processing.\n",
    "    Returns: list of (name, gray_image, width, height)\n",
    "    \"\"\"\n",
    "    processed = []\n",
    "    for name, img_bgr in template_data:\n",
    "        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        h, w = gray.shape\n",
    "        processed.append((name, gray, w, h))\n",
    "    return processed\n",
    "\n",
    "\n",
    "def load_geometry(geometry_path: str) -> dict:\n",
    "    with open(geometry_path, \"r\") as f:\n",
    "        geom = json.load(f)\n",
    "\n",
    "    cx = float(geom[\"ellipse\"][\"cx\"])\n",
    "    cy = float(geom[\"ellipse\"][\"cy\"])\n",
    "    rx = float(geom[\"ellipse\"][\"rx\"])\n",
    "    ry = float(geom[\"ellipse\"][\"ry\"])\n",
    "    rot_deg = float(geom[\"ellipse\"][\"rotation_deg\"])\n",
    "    zero_angle_deg = float(geom[\"zero_angle_deg\"])\n",
    "\n",
    "    outer_inward_pct = float(geom[\"halo\"][\"outer_inward_pct\"])\n",
    "    inner_inward_pct = float(geom[\"halo\"][\"inner_inward_pct\"])\n",
    "\n",
    "    outer_r_norm = 1.0 - outer_inward_pct\n",
    "    inner_r_norm = 1.0 - inner_inward_pct\n",
    "\n",
    "    return dict(\n",
    "        cx=cx, cy=cy, rx=rx, ry=ry,\n",
    "        ellipse_rot_deg=rot_deg,\n",
    "        zero_angle_deg=zero_angle_deg,\n",
    "        outer_r_norm=outer_r_norm,\n",
    "        inner_r_norm=inner_r_norm,\n",
    "        raw=geom\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ac224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TEMPLATE MATCHING LOGIC ---\n",
    "def find_best_match(target_gray, gray_templates):\n",
    "    \"\"\"\n",
    "    Optimized matcher for video. \n",
    "    Accepts PRE-CONVERTED gray templates to save time.\n",
    "    \"\"\"\n",
    "    best_match = {\n",
    "        \"score\": -1.0,\n",
    "        \"location\": None,\n",
    "        \"width\": 0,\n",
    "        \"height\": 0,\n",
    "        \"name\": \"\"\n",
    "    }\n",
    "\n",
    "    for name, tmpl_gray, w, h in gray_templates:\n",
    "        res = cv2.matchTemplate(target_gray, tmpl_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, max_val, _, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "        if max_val > best_match[\"score\"]:\n",
    "            best_match[\"score\"] = max_val\n",
    "            best_match[\"location\"] = max_loc\n",
    "            best_match[\"width\"] = w\n",
    "            best_match[\"height\"] = h\n",
    "            best_match[\"name\"] = name\n",
    "\n",
    "    return best_match\n",
    "\n",
    "\n",
    "def compute_zero_angle_for_frame(frame_bgr, gray_templates, geom: dict, min_score: float = 0.7):\n",
    "    \"\"\"\n",
    "    Uses template matching to find the 0-pocket template in this frame,\n",
    "    then returns zero_angle_deg for THIS frame (dynamic).\n",
    "    \"\"\"\n",
    "    target_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    best = find_best_match(target_gray, gray_templates)\n",
    "    if best[\"location\"] is None or best[\"score\"] < min_score:\n",
    "        raise RuntimeError(f\"Zero template match too weak: score={best['score']:.3f}\")\n",
    "\n",
    "    tlx, tly = best[\"location\"]\n",
    "    w, h = best[\"width\"], best[\"height\"]\n",
    "\n",
    "    zx = tlx + w / 2.0\n",
    "    zy = tly + h / 2.0\n",
    "\n",
    "    z_ang = ball_angle_deg(zx, zy, geom[\"cx\"], geom[\"cy\"])\n",
    "    return z_ang, (zx, zy), best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228dbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SHAPE FITTING & VIDEO PROCESSING ---\n",
    "def fit_ellipse(points_xy):\n",
    "    \"\"\"\n",
    "    Fit an ellipse to (x,y) points using OpenCV.\n",
    "    Needs >= 5 points.\n",
    "    Returns: (center(x,y), axes(rx, ry), angle_deg)\n",
    "    \"\"\"\n",
    "    pts = np.array(points_xy, dtype=np.float32).reshape(-1, 1, 2)\n",
    "    (cx, cy), (MA, ma), angle = cv2.fitEllipse(pts)\n",
    "    rx, ry = MA / 2.0, ma / 2.0\n",
    "    return (float(cx), float(cy)), (float(rx), float(ry)), float(angle)\n",
    "\n",
    "\n",
    "def distributed_frame_indices(total_frames: int, n: int):\n",
    "    \"\"\"\n",
    "    Returns n indices spread across [0, total_frames-1].\n",
    "    Ensures uniqueness and sorted order.\n",
    "    \"\"\"\n",
    "    n = int(max(1, n))\n",
    "    if total_frames <= 0:\n",
    "        return [0]\n",
    "    idx = np.linspace(0, max(0, total_frames-1), n, dtype=int)\n",
    "    idx = np.unique(idx)\n",
    "    return idx.tolist()\n",
    "\n",
    "\n",
    "def process_video_sampled_frames(\n",
    "    video_path: str,\n",
    "    template_folder: str,\n",
    "    n_samples: int = 30,\n",
    "    min_score: float = 0.60,\n",
    "    outer_inward_pct: float = 0.10,\n",
    "    inner_inward_pct: float = 0.30,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simplified pipeline:\n",
    "      1) Sample N distributed frames from the video\n",
    "      2) Template-match on ONLY those frames\n",
    "      3) Collect accepted center points\n",
    "      4) Fit ellipse (>=5 points) else circle fallback\n",
    "      5) Overlay the fitted shape on the FIRST frame\n",
    "\n",
    "    Params:\n",
    "      - n_samples: how many distributed frames to evaluate (higher = better fit, slower)\n",
    "      - min_score: NCC threshold\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Could not open video: {video_path}\")\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Grab the first frame for overlay output\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    ok, first_frame = cap.read()\n",
    "    if not ok:\n",
    "        cap.release()\n",
    "        raise RuntimeError(\"Could not read first frame.\")\n",
    "\n",
    "    # Load templates\n",
    "    templates_with_names = load_templates_with_names(template_folder)\n",
    "    gray_templates = preprocess_templates_for_video(templates_with_names)\n",
    "\n",
    "    sample_idxs = distributed_frame_indices(total_frames, n_samples)\n",
    "    print(f\"Total frames: {total_frames} | sampling {len(sample_idxs)} frames\")\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for idx in sample_idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        match = find_best_match(gray, gray_templates)\n",
    "\n",
    "        if match.get(\"location\") is None:\n",
    "            continue\n",
    "\n",
    "        score = float(match[\"score\"])\n",
    "        if score < min_score:\n",
    "            continue\n",
    "\n",
    "        # center coordinate\n",
    "        tlx, tly = match[\"location\"]\n",
    "        w, h = match[\"width\"], match[\"height\"]\n",
    "        cx = tlx + w / 2.0\n",
    "        cy = tly + h / 2.0\n",
    "\n",
    "        rows.append({\n",
    "            \"frame_idx\": int(idx),\n",
    "            \"center_x\": float(cx),\n",
    "            \"center_y\": float(cy),\n",
    "            \"score\": score,\n",
    "            \"template\": match.get(\"name\", \"\")\n",
    "        })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"Accepted points: {len(rows)}\")\n",
    "    if not rows:\n",
    "        print(\"No points accepted. Try lowering min_score or increasing n_samples.\")\n",
    "        return\n",
    "    \n",
    "    points_xy = [(r[\"center_x\"], r[\"center_y\"]) for r in rows]\n",
    "\n",
    "    # Fit ellipse if possible, else circle fallback\n",
    "    overlay = first_frame.copy()\n",
    "\n",
    "    if len(points_xy) >= 5:\n",
    "        (cx, cy), (rx, ry), angle = fit_ellipse(points_xy)\n",
    "        cv2.ellipse(\n",
    "            overlay,\n",
    "            (int(cx), int(cy)),\n",
    "            (int(rx), int(ry)),\n",
    "            angle,\n",
    "            0, 360,\n",
    "            (0, 0, 255),\n",
    "            3\n",
    "        )\n",
    "        cv2.circle(overlay, (int(cx), int(cy)), 4, (0, 255, 0), -1)\n",
    "\n",
    "        print(f\"\\nEllipse -> center=({cx:.1f},{cy:.1f}), axes=({rx:.1f},{ry:.1f}), angle={angle:.1f}°\")\n",
    "\n",
    "        # --- define zero reference angle using FIRST frame (stable reference) ---\n",
    "        first_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "        zero_match = find_best_match(first_gray, gray_templates)\n",
    "\n",
    "        if zero_match.get(\"location\") is None:\n",
    "            raise RuntimeError(\"Could not find zero template on first frame; cannot compute zero reference angle.\")\n",
    "\n",
    "        tlx, tly = zero_match[\"location\"]\n",
    "        w, h = zero_match[\"width\"], zero_match[\"height\"]\n",
    "        zero_x = tlx + w / 2.0\n",
    "        zero_y = tly + h / 2.0\n",
    "\n",
    "        dx0 = zero_x - cx\n",
    "        dy0 = zero_y - cy\n",
    "\n",
    "        # angle in image space (y axis inverted)\n",
    "        zero_angle_deg = (np.degrees(np.arctan2(-dy0, dx0)) % 360.0)\n",
    "\n",
    "        print(f\"Zero reference on first frame -> (x,y)=({zero_x:.1f},{zero_y:.1f}) angle={zero_angle_deg:.2f}° score={zero_match['score']:.3f}\")\n",
    "\n",
    "        # export geometry handoff artifact\n",
    "        geometry = {\n",
    "            \"ellipse\": {\n",
    "                \"cx\": float(cx),\n",
    "                \"cy\": float(cy),\n",
    "                \"rx\": float(rx),\n",
    "                \"ry\": float(ry),\n",
    "                \"rotation_deg\": float(angle),\n",
    "            },\n",
    "            \"zero_angle_deg\": float(zero_angle_deg),\n",
    "            \"halo\": {\n",
    "                \"outer_inward_pct\": float(outer_inward_pct), \n",
    "                \"inner_inward_pct\": float(inner_inward_pct)\n",
    "            },\n",
    "            \"wheel\": {\n",
    "                \"type\": \"EU\",\n",
    "                \"pockets\": 37\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(\"wheel_geometry.json\", \"w\") as f:\n",
    "            json.dump(geometry, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GEOMETRY & INFERENCE ---\n",
    "\n",
    "def ensure_geometry(\n",
    "    setup_video_path: str,\n",
    "    templates_dir: str,\n",
    "    geometry_path: str | None,\n",
    "    n_samples: int,\n",
    "    min_score: float,\n",
    "    outer_inward_pct: float,\n",
    "    inner_inward_pct: float,\n",
    "    output_path_if_built: str = \"wheel_geometry.json\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    If geometry_path is provided and exists, use it.\n",
    "    Otherwise build geometry and return the path of the newly written JSON.\n",
    "    \"\"\"\n",
    "    if geometry_path and os.path.isfile(geometry_path):\n",
    "        print(f\"Using existing geometry: {geometry_path}\")\n",
    "        return geometry_path\n",
    "\n",
    "    print(\"No geometry provided (or file missing). Building geometry now...\")\n",
    "    process_video_sampled_frames(\n",
    "        video_path=setup_video_path,\n",
    "        template_folder=templates_dir,\n",
    "        n_samples=n_samples,\n",
    "        min_score=min_score,\n",
    "        outer_inward_pct=outer_inward_pct,\n",
    "        inner_inward_pct=inner_inward_pct\n",
    "    )\n",
    "    # ^ your function currently writes \"wheel_geometry.json\" in cwd (based on your calls)\n",
    "\n",
    "    if not os.path.isfile(output_path_if_built):\n",
    "        raise FileNotFoundError(f\"Expected geometry file was not created: {output_path_if_built}\")\n",
    "\n",
    "    return output_path_if_built\n",
    "\n",
    "\n",
    "EUROPEAN_WHEEL_ORDER = [\n",
    "    0,\n",
    "    32, 15, 19, 4, 21, 2, 25, 17, 34,\n",
    "    6, 27, 13, 36, 11, 30, 8, 23, 10,\n",
    "    5, 24, 16, 33, 1, 20, 14, 31,\n",
    "    9, 22, 18, 29, 7, 28, 12,\n",
    "    35, 3, 26\n",
    "]\n",
    "\n",
    "AMERICAN_WHEEL_ORDER = [\n",
    "    0, 28, 9, 26, 30, 11, 7, 20, 32, 17,\n",
    "    5, 22, 34, 15, 3, 24, 36, 13, 1, \"00\",\n",
    "    27, 10, 25, 29, 12, 8, 19, 31, 18,\n",
    "    6, 21, 33, 16, 4, 23, 35, 14, 2\n",
    "]\n",
    "\n",
    "def get_wheel_order(wheel_type: str):\n",
    "    wheel_type = wheel_type.upper().strip()\n",
    "    if wheel_type in (\"EU\", \"EUROPE\", \"EUROPEAN\"):\n",
    "        return EUROPEAN_WHEEL_ORDER\n",
    "    if wheel_type in (\"US\", \"USA\", \"AMERICAN\"):\n",
    "        return AMERICAN_WHEEL_ORDER\n",
    "    raise ValueError(\"wheel_type must be 'EU' or 'US'\")\n",
    "\n",
    "\n",
    "def rotate_point_to_ellipse_axes(x, y, cx, cy, rot_deg):\n",
    "    \"\"\"Rotate (x,y) around (cx,cy) by -rot_deg so ellipse becomes axis-aligned.\"\"\"\n",
    "    theta = math.radians(rot_deg)\n",
    "    tx, ty = x - cx, y - cy\n",
    "    cos_t, sin_t = math.cos(theta), math.sin(theta)\n",
    "    xr =  tx * cos_t + ty * sin_t\n",
    "    yr = -tx * sin_t + ty * cos_t\n",
    "    return xr, yr\n",
    "\n",
    "\n",
    "def ball_angle_deg(x, y, cx, cy) -> float:\n",
    "    \"\"\"0° = +x to the right, CCW positive (image y goes down so we flip).\"\"\"\n",
    "    dx = x - cx\n",
    "    dy = y - cy\n",
    "    return (math.degrees(math.atan2(-dy, dx)) % 360.0)\n",
    "\n",
    "\n",
    "def r_norm_in_ellipse_space(x, y, geom: dict) -> float:\n",
    "    xr, yr = rotate_point_to_ellipse_axes(x, y, geom[\"cx\"], geom[\"cy\"], geom[\"ellipse_rot_deg\"])\n",
    "    # normalized radius in ellipse coordinates\n",
    "    return math.sqrt((xr / geom[\"rx\"])**2 + (yr / geom[\"ry\"])**2)\n",
    "\n",
    "\n",
    "def is_point_in_halo(x, y, geom: dict) -> bool:\n",
    "    r = r_norm_in_ellipse_space(x, y, geom)\n",
    "    return (geom[\"inner_r_norm\"] <= r <= geom[\"outer_r_norm\"])\n",
    "\n",
    "\n",
    "def angle_to_pocket_index_using_zero_center(ball_ang_deg: float, zero_center_deg: float, n_pockets: int) -> int:\n",
    "    \"\"\"\n",
    "    Assumes zero_center_deg points to CENTER of pocket 0.\n",
    "    Converts to a boundary reference by subtracting half a sector.\n",
    "    \"\"\"\n",
    "    sector = 360.0 / n_pockets\n",
    "    zero_boundary = (zero_center_deg - 0.5 * sector) % 360.0\n",
    "    rel = (ball_ang_deg - zero_boundary) % 360.0\n",
    "    idx = int(rel // sector)\n",
    "    return max(0, min(n_pockets - 1, idx))\n",
    "\n",
    "\n",
    "def pocket_value_from_angle(ball_ang_deg: float, zero_center_deg: float, wheel_order):\n",
    "    idx = angle_to_pocket_index_using_zero_center(ball_ang_deg, zero_center_deg, n_pockets=len(wheel_order))\n",
    "    return idx, wheel_order[idx]\n",
    "\n",
    "\n",
    "def compute_zero_angle_for_frame(frame_bgr, gray_templates, geom: dict, min_score: float = 0.7):\n",
    "    target_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    best = find_best_match(target_gray, gray_templates)  # your existing helper\n",
    "    if best[\"location\"] is None or best[\"score\"] < min_score:\n",
    "        raise RuntimeError(f\"Zero template match too weak: score={best['score']:.3f}\")\n",
    "\n",
    "    tlx, tly = best[\"location\"]\n",
    "    w, h = best[\"width\"], best[\"height\"]\n",
    "    zx = tlx + w / 2.0\n",
    "    zy = tly + h / 2.0\n",
    "\n",
    "    z_ang = ball_angle_deg(zx, zy, geom[\"cx\"], geom[\"cy\"])\n",
    "    return z_ang, (zx, zy), best\n",
    "\n",
    "\n",
    "def run_ball_landing_inference(\n",
    "    video_path: str,\n",
    "    model_path: str,\n",
    "    geom: dict,\n",
    "    gray_templates,\n",
    "    wheel_type: str = \"EU\",\n",
    "    conf_thres: float = 0.35,\n",
    "    iou_thres: float = 0.70,\n",
    "    device=0,\n",
    "    ball_class_id: int = 0,\n",
    "    landing_seconds_required: float = 2.5,\n",
    "    min_zero_score: float = 0.70\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs YOLO inference on the video to detect when the ball has landed in the halo.\n",
    "    Uses the geometry to determine if detected ball is in the halo for a sustained period.\n",
    "    \"\"\"\n",
    "    wheel_order = get_wheel_order(wheel_type)\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Could not open video: {video_path}\")\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    cap.release()\n",
    "\n",
    "    frames_required = int(round(landing_seconds_required * fps))\n",
    "    model = YOLO(str(model_path))\n",
    "\n",
    "    consecutive = 0\n",
    "    landed = False\n",
    "    landing_frame_idx = None\n",
    "    landing_ball_xy = None\n",
    "    landing_ball_angle = None\n",
    "    landing_pocket_idx = None\n",
    "    landing_pocket_value = None\n",
    "\n",
    "    frame_idx = -1\n",
    "\n",
    "    for r in model.predict(\n",
    "        source=str(video_path),\n",
    "        stream=True,\n",
    "        conf=conf_thres,\n",
    "        iou=iou_thres,\n",
    "        device=device\n",
    "    ):\n",
    "        frame_idx += 1\n",
    "\n",
    "        if r.boxes is None or len(r.boxes) == 0:\n",
    "            consecutive = 0\n",
    "            continue\n",
    "\n",
    "        # pick best ball detection (class id + highest conf)\n",
    "        best = None\n",
    "        for b in r.boxes:\n",
    "            cls_id = int(b.cls[0])\n",
    "            if cls_id != ball_class_id:\n",
    "                continue\n",
    "            conf = float(b.conf[0])\n",
    "            if best is None or conf > best[\"conf\"]:\n",
    "                x1, y1, x2, y2 = map(float, b.xyxy[0])\n",
    "                best = dict(conf=conf, xyxy=(x1, y1, x2, y2))\n",
    "\n",
    "        if best is None:\n",
    "            consecutive = 0\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = best[\"xyxy\"]\n",
    "        bx = (x1 + x2) / 2.0\n",
    "        by = (y1 + y2) / 2.0\n",
    "\n",
    "        in_halo = is_point_in_halo(bx, by, geom)\n",
    "\n",
    "        if in_halo:\n",
    "            consecutive += 1\n",
    "        else:\n",
    "            consecutive = 0\n",
    "\n",
    "        if (not landed) and consecutive >= frames_required:\n",
    "            landed = True\n",
    "            landing_frame_idx = frame_idx\n",
    "            landing_ball_xy = (bx, by)\n",
    "            \n",
    "            landing_ball_angle = ball_angle_deg(bx, by, geom[\"cx\"], geom[\"cy\"])\n",
    "\n",
    "            # --- NEW: read the landing frame from the video ---\n",
    "            cap2 = cv2.VideoCapture(str(video_path))\n",
    "            cap2.set(cv2.CAP_PROP_POS_FRAMES, landing_frame_idx)\n",
    "            ok2, landing_frame = cap2.read()\n",
    "            cap2.release()\n",
    "            if not ok2:\n",
    "                raise RuntimeError(f\"Could not read landing frame {landing_frame_idx} to compute dynamic zero angle.\")\n",
    "\n",
    "            # --- NEW: compute ZERO angle on the landing frame (dynamic) ---\n",
    "            zero_angle_landing, zero_xy, zero_match = compute_zero_angle_for_frame(\n",
    "                landing_frame, gray_templates, geom, min_score=min_zero_score\n",
    "            )\n",
    "\n",
    "            # --- NEW: compute pocket using dynamic zero (center-based) ---\n",
    "            landing_pocket_idx = angle_to_pocket_index_using_zero_center(\n",
    "                landing_ball_angle, zero_angle_landing, n_pockets=len(wheel_order)\n",
    "            )\n",
    "            landing_pocket_value = wheel_order[landing_pocket_idx]\n",
    "\n",
    "            # (optional) store debug\n",
    "            landing_zero_angle = zero_angle_landing\n",
    "            landing_zero_xy = zero_xy\n",
    "            landing_zero_score = float(zero_match[\"score\"])\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "    return dict(\n",
    "        landed=landed,\n",
    "        landing_frame_idx=landing_frame_idx,\n",
    "        landing_ball_xy=landing_ball_xy,\n",
    "        landing_ball_angle=landing_ball_angle,\n",
    "        landing_pocket_idx=landing_pocket_idx,\n",
    "        landing_pocket_value=landing_pocket_value,\n",
    "        wheel_type=wheel_type,\n",
    "        frames_required=frames_required,\n",
    "        zero_angle_landing=landing_zero_angle if landed else None,\n",
    "        zero_xy=landing_zero_xy if landed else None,\n",
    "        zero_score=landing_zero_score if landed else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- DEBUG VISUALIZATION ---\n",
    "def debug_draw_ellipse_from_geometry(\n",
    "    video_path: str, \n",
    "    geometry_path: str, \n",
    "    frame_index: int = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    Visual sanity check:\n",
    "    - Draw fitted ellipse\n",
    "    - Draw center point\n",
    "    - Draw zero-angle ray\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Failed to open video: {video_path}\")\n",
    "\n",
    "    # seek to frame\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ok:\n",
    "        raise RuntimeError(f\"Failed to read frame {frame_index}\")\n",
    "\n",
    "    with open(geometry_path, \"r\") as f:\n",
    "        geom = json.load(f)\n",
    "\n",
    "    cx = geom[\"ellipse\"][\"cx\"]\n",
    "    cy = geom[\"ellipse\"][\"cy\"]\n",
    "    rx = geom[\"ellipse\"][\"rx\"]\n",
    "    ry = geom[\"ellipse\"][\"ry\"]\n",
    "    rot = geom[\"ellipse\"][\"rotation_deg\"]\n",
    "    zero_angle = geom[\"zero_angle_deg\"]\n",
    "\n",
    "    overlay = frame.copy()\n",
    "\n",
    "    # draw fitted ellipse\n",
    "    cv2.ellipse(\n",
    "        overlay,\n",
    "        (int(cx), int(cy)),\n",
    "        (int(rx), int(ry)),\n",
    "        rot,\n",
    "        0, 360,\n",
    "        (0, 255, 0),\n",
    "        2\n",
    "    )\n",
    "\n",
    "    # draw center\n",
    "    cv2.circle(overlay, (int(cx), int(cy)), 4, (0, 255, 0), -1)\n",
    "\n",
    "    # draw zero-angle ray\n",
    "    r = int(max(rx, ry) * 1.1)\n",
    "    x2 = int(cx + r * np.cos(np.radians(zero_angle)))\n",
    "    y2 = int(cy - r * np.sin(np.radians(zero_angle)))  # minus because image y-axis\n",
    "    cv2.line(overlay, (int(cx), int(cy)), (x2, y2), (0, 255, 255), 2)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Ellipse Sanity Check\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def debug_draw_halo_from_geometry(\n",
    "    video_path: str,\n",
    "    geometry_path: str,\n",
    "    frame_index: int = 0,\n",
    "    show_filled_band: bool = True,\n",
    "    band_alpha: float = 0.35\n",
    "):\n",
    "    \"\"\"\n",
    "    Visual sanity check:\n",
    "    - Draw fitted ellipse\n",
    "    - Draw halo outer+inner boundary ellipses (computed from inward %)\n",
    "    - Optionally render the halo band as a filled mask overlay\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Failed to open video: {video_path}\")\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ok:\n",
    "        raise RuntimeError(f\"Failed to read frame {frame_index}\")\n",
    "\n",
    "    with open(geometry_path, \"r\") as f:\n",
    "        geom = json.load(f)\n",
    "\n",
    "    cx = float(geom[\"ellipse\"][\"cx\"])\n",
    "    cy = float(geom[\"ellipse\"][\"cy\"])\n",
    "    rx = float(geom[\"ellipse\"][\"rx\"])\n",
    "    ry = float(geom[\"ellipse\"][\"ry\"])\n",
    "    rot = float(geom[\"ellipse\"][\"rotation_deg\"])\n",
    "\n",
    "    outer_inward = float(geom[\"halo\"][\"outer_inward_pct\"])\n",
    "    inner_inward = float(geom[\"halo\"][\"inner_inward_pct\"])\n",
    "\n",
    "    # Halo boundaries are \"shrunk\" versions of the fitted ellipse\n",
    "    # outer boundary = slightly inside outer rim\n",
    "    # inner boundary = further inside\n",
    "    outer_rx = rx * (1.0 - outer_inward)\n",
    "    outer_ry = ry * (1.0 - outer_inward)\n",
    "\n",
    "    inner_rx = rx * (1.0 - inner_inward)\n",
    "    inner_ry = ry * (1.0 - inner_inward)\n",
    "\n",
    "    overlay = frame.copy()\n",
    "\n",
    "    # Draw fitted ellipse (baseline)\n",
    "    cv2.ellipse(overlay, (int(cx), int(cy)), (int(rx), int(ry)), rot, 0, 360, (0, 255, 0), 2)\n",
    "\n",
    "    # Draw halo boundaries\n",
    "    cv2.ellipse(overlay, (int(cx), int(cy)), (int(outer_rx), int(outer_ry)), rot, 0, 360, (255, 255, 0), 2)  # outer halo line\n",
    "    cv2.ellipse(overlay, (int(cx), int(cy)), (int(inner_rx), int(inner_ry)), rot, 0, 360, (0, 255, 255), 2)  # inner halo line\n",
    "\n",
    "    # Optional: filled band mask for the halo region\n",
    "    if show_filled_band:\n",
    "        mask_outer = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "        mask_inner = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "\n",
    "        cv2.ellipse(mask_outer, (int(cx), int(cy)), (int(outer_rx), int(outer_ry)), rot, 0, 360, 255, -1)\n",
    "        cv2.ellipse(mask_inner, (int(cx), int(cy)), (int(inner_rx), int(inner_ry)), rot, 0, 360, 255, -1)\n",
    "\n",
    "        band_mask = cv2.subtract(mask_outer, mask_inner)\n",
    "\n",
    "        # Paint the band on a colored layer (red-ish) then alpha blend\n",
    "        color_layer = np.zeros_like(frame, dtype=np.uint8)\n",
    "        color_layer[band_mask > 0] = (0, 0, 255)\n",
    "\n",
    "        overlay = cv2.addWeighted(overlay, 1.0, color_layer, band_alpha, 0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Halo Sanity Check (outer/inner boundaries + optional band)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2968e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "# 1) Pick inputs\n",
    "_, VIDEO_PATH = pick_video_cv2(title=\"Select Input Video for Main Execution\")\n",
    "_, setup_video_path = pick_video_cv2(title=\"Select Input Video for Wheel Geometry Setup\")\n",
    "templates_dir = pick_folder(title=\"Select Templates Folder\")\n",
    "\n",
    "MODEL_PATH = r\"C:\\Users\\Gabriel\\Documents\\Dissertation\\Code\\models\\yolo\\RD2_Model.pt\"\n",
    "\n",
    "# Wheel geometry setup parameters\n",
    "N_SAMPLES = 10\n",
    "MIN_SCORE = 0.80\n",
    "OUTER_INWARD_PCT = 0.10\n",
    "INNER_INWARD_PCT = 0.30\n",
    "\n",
    "# Inference parameters for the main execution\n",
    "CONF_THRES = 0.35\n",
    "IOU_THRES  = 0.70\n",
    "\n",
    "# Optional\n",
    "GEOMETRY_PATH = None\n",
    "# GEOMETRY_PATH = r\"C:\\Users\\Gabriel\\Documents\\Dissertation\\Code\\notebooks\\roulette_cv\\wheel_geometry.json\n",
    "\n",
    "# 2) Ensure geometry exists\n",
    "geometry_path = ensure_geometry(\n",
    "    setup_video_path=setup_video_path,\n",
    "    templates_dir=templates_dir,\n",
    "    geometry_path=GEOMETRY_PATH,\n",
    "    n_samples=N_SAMPLES,\n",
    "    min_score=MIN_SCORE,\n",
    "    outer_inward_pct=OUTER_INWARD_PCT,\n",
    "    inner_inward_pct=INNER_INWARD_PCT,\n",
    ")\n",
    "\n",
    "geom = load_geometry(geometry_path)\n",
    "\n",
    "# 3) Inference\n",
    "result = run_ball_landing_inference(\n",
    "    video_path=VIDEO_PATH,\n",
    "    model_path=MODEL_PATH,\n",
    "    geom=geom,\n",
    "    wheel_type=\"EU\",\n",
    "    conf_thres=CONF_THRES,\n",
    "    iou_thres=IOU_THRES,\n",
    "    device=0, # 0 for GPU, \"cpu\" for CPU\n",
    "    ball_class_id=0,\n",
    "    landing_seconds_required=2.5,\n",
    "    gray_templates=gray_templates\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
