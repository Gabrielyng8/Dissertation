{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e91d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils.file_dialog_utils import pick_video_cv2, pick_folder\n",
    "\n",
    "# --- LOADING & PREPARATION ---\n",
    "def load_templates_with_names(folder_path):\n",
    "    \"\"\"\n",
    "    Loads templates and keeps their filenames.\n",
    "    Returns: list of (filename, image_bgr)\n",
    "    \"\"\"\n",
    "    paths = sorted(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
    "    template_data = []\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is not None:\n",
    "            filename = os.path.basename(p)\n",
    "            template_data.append((filename, img))\n",
    "    return template_data\n",
    "\n",
    "\n",
    "def preprocess_templates_for_video(template_data):\n",
    "    \"\"\"\n",
    "    Converts BGR templates to Grayscale ONCE to speed up video processing.\n",
    "    Returns: list of (name, gray_image, width, height)\n",
    "    \"\"\"\n",
    "    processed = []\n",
    "    for name, img_bgr in template_data:\n",
    "        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        h, w = gray.shape\n",
    "        processed.append((name, gray, w, h))\n",
    "    return processed\n",
    "\n",
    "# --- TEMPLATE MATCHING LOGIC ---\n",
    "def find_best_match(target_gray, gray_templates):\n",
    "    \"\"\"\n",
    "    Optimized matcher for video. \n",
    "    Accepts PRE-CONVERTED gray templates to save time.\n",
    "    \"\"\"\n",
    "    best_match = {\n",
    "        \"score\": -1.0,\n",
    "        \"location\": None,\n",
    "        \"width\": 0,\n",
    "        \"height\": 0,\n",
    "        \"name\": \"\"\n",
    "    }\n",
    "\n",
    "    for name, tmpl_gray, w, h in gray_templates:\n",
    "        res = cv2.matchTemplate(target_gray, tmpl_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, max_val, _, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "        if max_val > best_match[\"score\"]:\n",
    "            best_match[\"score\"] = max_val\n",
    "            best_match[\"location\"] = max_loc\n",
    "            best_match[\"width\"] = w\n",
    "            best_match[\"height\"] = h\n",
    "            best_match[\"name\"] = name\n",
    "\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228dbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SHAPE FITTING & VIDEO PROCESSING ---\n",
    "def fit_ellipse(points_xy):\n",
    "    \"\"\"\n",
    "    Fit an ellipse to (x,y) points using OpenCV.\n",
    "    Needs >= 5 points.\n",
    "    Returns: (center(x,y), axes(rx, ry), angle_deg)\n",
    "    \"\"\"\n",
    "    pts = np.array(points_xy, dtype=np.float32).reshape(-1, 1, 2)\n",
    "    (cx, cy), (MA, ma), angle = cv2.fitEllipse(pts)\n",
    "    rx, ry = MA / 2.0, ma / 2.0\n",
    "    return (float(cx), float(cy)), (float(rx), float(ry)), float(angle)\n",
    "\n",
    "\n",
    "def distributed_frame_indices(total_frames: int, n: int):\n",
    "    \"\"\"\n",
    "    Returns n indices spread across [0, total_frames-1].\n",
    "    Ensures uniqueness and sorted order.\n",
    "    \"\"\"\n",
    "    n = int(max(1, n))\n",
    "    if total_frames <= 0:\n",
    "        return [0]\n",
    "    idx = np.linspace(0, max(0, total_frames-1), n, dtype=int)\n",
    "    idx = np.unique(idx)\n",
    "    return idx.tolist()\n",
    "\n",
    "\n",
    "def process_video_sampled_frames(\n",
    "    video_path: str,\n",
    "    template_folder: str,\n",
    "    n_samples: int = 30,\n",
    "    min_score: float = 0.60,\n",
    "    outer_inward_pct: float = 0.10,\n",
    "    inner_inward_pct: float = 0.30,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simplified pipeline:\n",
    "      1) Sample N distributed frames from the video\n",
    "      2) Template-match on ONLY those frames\n",
    "      3) Collect accepted center points\n",
    "      4) Fit ellipse (>=5 points) else circle fallback\n",
    "      5) Overlay the fitted shape on the FIRST frame\n",
    "\n",
    "    Params:\n",
    "      - n_samples: how many distributed frames to evaluate (higher = better fit, slower)\n",
    "      - min_score: NCC threshold\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Could not open video: {video_path}\")\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Grab the first frame for overlay output\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    ok, first_frame = cap.read()\n",
    "    if not ok:\n",
    "        cap.release()\n",
    "        raise RuntimeError(\"Could not read first frame.\")\n",
    "\n",
    "    # Load templates\n",
    "    templates_with_names = load_templates_with_names(template_folder)\n",
    "    gray_templates = preprocess_templates_for_video(templates_with_names)\n",
    "\n",
    "    sample_idxs = distributed_frame_indices(total_frames, n_samples)\n",
    "    print(f\"Total frames: {total_frames} | sampling {len(sample_idxs)} frames\")\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for idx in sample_idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        match = find_best_match(gray, gray_templates)\n",
    "\n",
    "        if match.get(\"location\") is None:\n",
    "            continue\n",
    "\n",
    "        score = float(match[\"score\"])\n",
    "        if score < min_score:\n",
    "            continue\n",
    "\n",
    "        # center coordinate\n",
    "        tlx, tly = match[\"location\"]\n",
    "        w, h = match[\"width\"], match[\"height\"]\n",
    "        cx = tlx + w / 2.0\n",
    "        cy = tly + h / 2.0\n",
    "\n",
    "        rows.append({\n",
    "            \"frame_idx\": int(idx),\n",
    "            \"center_x\": float(cx),\n",
    "            \"center_y\": float(cy),\n",
    "            \"score\": score,\n",
    "            \"template\": match.get(\"name\", \"\")\n",
    "        })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"Accepted points: {len(rows)}\")\n",
    "    if not rows:\n",
    "        print(\"No points accepted. Try lowering min_score or increasing n_samples.\")\n",
    "        return\n",
    "    \n",
    "    points_xy = [(r[\"center_x\"], r[\"center_y\"]) for r in rows]\n",
    "\n",
    "    # Fit ellipse if possible, else circle fallback\n",
    "    overlay = first_frame.copy()\n",
    "\n",
    "    if len(points_xy) >= 5:\n",
    "        (cx, cy), (rx, ry), angle = fit_ellipse(points_xy)\n",
    "        cv2.ellipse(\n",
    "            overlay,\n",
    "            (int(cx), int(cy)),\n",
    "            (int(rx), int(ry)),\n",
    "            angle,\n",
    "            0, 360,\n",
    "            (0, 0, 255),\n",
    "            3\n",
    "        )\n",
    "        cv2.circle(overlay, (int(cx), int(cy)), 4, (0, 255, 0), -1)\n",
    "\n",
    "        print(f\"\\nEllipse -> center=({cx:.1f},{cy:.1f}), axes=({rx:.1f},{ry:.1f}), angle={angle:.1f}°\")\n",
    "\n",
    "        # --- define zero reference angle using FIRST frame (stable reference) ---\n",
    "        first_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "        zero_match = find_best_match(first_gray, gray_templates)\n",
    "\n",
    "        if zero_match.get(\"location\") is None:\n",
    "            raise RuntimeError(\"Could not find zero template on first frame; cannot compute zero reference angle.\")\n",
    "\n",
    "        tlx, tly = zero_match[\"location\"]\n",
    "        w, h = zero_match[\"width\"], zero_match[\"height\"]\n",
    "        zero_x = tlx + w / 2.0\n",
    "        zero_y = tly + h / 2.0\n",
    "\n",
    "        dx0 = zero_x - cx\n",
    "        dy0 = zero_y - cy\n",
    "\n",
    "        # angle in image space (y axis inverted)\n",
    "        zero_angle_deg = (np.degrees(np.arctan2(-dy0, dx0)) % 360.0)\n",
    "\n",
    "        print(f\"Zero reference on first frame -> (x,y)=({zero_x:.1f},{zero_y:.1f}) angle={zero_angle_deg:.2f}° score={zero_match['score']:.3f}\")\n",
    "\n",
    "        # export geometry handoff artifact\n",
    "        geometry = {\n",
    "            \"ellipse\": {\n",
    "                \"cx\": float(cx),\n",
    "                \"cy\": float(cy),\n",
    "                \"rx\": float(rx),\n",
    "                \"ry\": float(ry),\n",
    "                \"rotation_deg\": float(angle),\n",
    "            },\n",
    "            \"zero_angle_deg\": float(zero_angle_deg),\n",
    "            \"halo\": {\n",
    "                \"outer_inward_pct\": float(outer_inward_pct), \n",
    "                \"inner_inward_pct\": float(inner_inward_pct)\n",
    "            },\n",
    "            \"wheel\": {\n",
    "                \"type\": \"EU\",\n",
    "                \"pockets\": 37\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(\"wheel_geometry.json\", \"w\") as f:\n",
    "            json.dump(geometry, f, indent=2)\n",
    "\n",
    "        print(\"\\nSaved wheel_geometry.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- DEBUG VISUALIZATION ---\n",
    "def debug_draw_ellipse_from_geometry(\n",
    "    video_path: str, \n",
    "    geometry_path: str, \n",
    "    frame_index: int = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    Visual sanity check:\n",
    "    - Draw fitted ellipse\n",
    "    - Draw center point\n",
    "    - Draw zero-angle ray\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Failed to open video: {video_path}\")\n",
    "\n",
    "    # seek to frame\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ok:\n",
    "        raise RuntimeError(f\"Failed to read frame {frame_index}\")\n",
    "\n",
    "    with open(geometry_path, \"r\") as f:\n",
    "        geom = json.load(f)\n",
    "\n",
    "    cx = geom[\"ellipse\"][\"cx\"]\n",
    "    cy = geom[\"ellipse\"][\"cy\"]\n",
    "    rx = geom[\"ellipse\"][\"rx\"]\n",
    "    ry = geom[\"ellipse\"][\"ry\"]\n",
    "    rot = geom[\"ellipse\"][\"rotation_deg\"]\n",
    "    zero_angle = geom[\"zero_angle_deg\"]\n",
    "\n",
    "    overlay = frame.copy()\n",
    "\n",
    "    # draw fitted ellipse\n",
    "    cv2.ellipse(\n",
    "        overlay,\n",
    "        (int(cx), int(cy)),\n",
    "        (int(rx), int(ry)),\n",
    "        rot,\n",
    "        0, 360,\n",
    "        (0, 255, 0),\n",
    "        2\n",
    "    )\n",
    "\n",
    "    # draw center\n",
    "    cv2.circle(overlay, (int(cx), int(cy)), 4, (0, 255, 0), -1)\n",
    "\n",
    "    # draw zero-angle ray\n",
    "    r = int(max(rx, ry) * 1.1)\n",
    "    x2 = int(cx + r * np.cos(np.radians(zero_angle)))\n",
    "    y2 = int(cy - r * np.sin(np.radians(zero_angle)))  # minus because image y-axis\n",
    "    cv2.line(overlay, (int(cx), int(cy)), (x2, y2), (0, 255, 255), 2)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Ellipse Sanity Check\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def debug_draw_halo_from_geometry(\n",
    "    video_path: str,\n",
    "    geometry_path: str,\n",
    "    frame_index: int = 0,\n",
    "    show_filled_band: bool = True,\n",
    "    band_alpha: float = 0.35\n",
    "):\n",
    "    \"\"\"\n",
    "    Visual sanity check:\n",
    "    - Draw fitted ellipse\n",
    "    - Draw halo outer+inner boundary ellipses (computed from inward %)\n",
    "    - Optionally render the halo band as a filled mask overlay\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Failed to open video: {video_path}\")\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ok:\n",
    "        raise RuntimeError(f\"Failed to read frame {frame_index}\")\n",
    "\n",
    "    with open(geometry_path, \"r\") as f:\n",
    "        geom = json.load(f)\n",
    "\n",
    "    cx = float(geom[\"ellipse\"][\"cx\"])\n",
    "    cy = float(geom[\"ellipse\"][\"cy\"])\n",
    "    rx = float(geom[\"ellipse\"][\"rx\"])\n",
    "    ry = float(geom[\"ellipse\"][\"ry\"])\n",
    "    rot = float(geom[\"ellipse\"][\"rotation_deg\"])\n",
    "\n",
    "    outer_inward = float(geom[\"halo\"][\"outer_inward_pct\"])\n",
    "    inner_inward = float(geom[\"halo\"][\"inner_inward_pct\"])\n",
    "\n",
    "    # Halo boundaries are \"shrunk\" versions of the fitted ellipse\n",
    "    # outer boundary = slightly inside outer rim\n",
    "    # inner boundary = further inside\n",
    "    outer_rx = rx * (1.0 - outer_inward)\n",
    "    outer_ry = ry * (1.0 - outer_inward)\n",
    "\n",
    "    inner_rx = rx * (1.0 - inner_inward)\n",
    "    inner_ry = ry * (1.0 - inner_inward)\n",
    "\n",
    "    overlay = frame.copy()\n",
    "\n",
    "    # Draw fitted ellipse (baseline)\n",
    "    cv2.ellipse(overlay, (int(cx), int(cy)), (int(rx), int(ry)), rot, 0, 360, (0, 255, 0), 2)\n",
    "\n",
    "    # Draw halo boundaries\n",
    "    cv2.ellipse(overlay, (int(cx), int(cy)), (int(outer_rx), int(outer_ry)), rot, 0, 360, (255, 255, 0), 2)  # outer halo line\n",
    "    cv2.ellipse(overlay, (int(cx), int(cy)), (int(inner_rx), int(inner_ry)), rot, 0, 360, (0, 255, 255), 2)  # inner halo line\n",
    "\n",
    "    # Optional: filled band mask for the halo region\n",
    "    if show_filled_band:\n",
    "        mask_outer = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "        mask_inner = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "\n",
    "        cv2.ellipse(mask_outer, (int(cx), int(cy)), (int(outer_rx), int(outer_ry)), rot, 0, 360, 255, -1)\n",
    "        cv2.ellipse(mask_inner, (int(cx), int(cy)), (int(inner_rx), int(inner_ry)), rot, 0, 360, 255, -1)\n",
    "\n",
    "        band_mask = cv2.subtract(mask_outer, mask_inner)\n",
    "\n",
    "        # Paint the band on a colored layer (red-ish) then alpha blend\n",
    "        color_layer = np.zeros_like(frame, dtype=np.uint8)\n",
    "        color_layer[band_mask > 0] = (0, 0, 255)\n",
    "\n",
    "        overlay = cv2.addWeighted(overlay, 1.0, color_layer, band_alpha, 0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Halo Sanity Check (outer/inner boundaries + optional band)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2968e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN EXECUTION ---\n",
    "_, input_video_path = pick_video_cv2(title=\"Select Input Video for Wheel Geometry Setup\")\n",
    "templates_dir = pick_folder(title=\"Select Template Folder\")\n",
    "\n",
    "N_SAMPLES = 10\n",
    "MIN_SCORE = 0.80\n",
    "OUTER_INWARD_PCT = 0.10\n",
    "INNER_INWARD_PCT = 0.30\n",
    "\n",
    "process_video_sampled_frames(\n",
    "    video_path=input_video_path,\n",
    "    template_folder=templates_dir,\n",
    "    n_samples=N_SAMPLES,\n",
    "    min_score=MIN_SCORE,\n",
    "    outer_inward_pct=OUTER_INWARD_PCT,\n",
    "    inner_inward_pct=INNER_INWARD_PCT\n",
    ")\n",
    "\n",
    "debug_draw_ellipse_from_geometry(input_video_path, \"wheel_geometry.json\", frame_index=0)\n",
    "debug_draw_halo_from_geometry(input_video_path, \"wheel_geometry.json\", frame_index=0, show_filled_band=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
